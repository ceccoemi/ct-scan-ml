{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from statistics import mean\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import tfrecord_dataset, kfolds, train_test_split\n",
    "from train import train_model\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from plot import plot_slice, plot_volume_animation\n",
    "from config import (\n",
    "    SMALL_NEG_TFRECORD,\n",
    "    SMALL_POS_TFRECORD,\n",
    "    BIG_NEG_TFRECORD,\n",
    "    BIG_POS_TFRECORD,\n",
    "    SMALL_PATCH_SHAPE,\n",
    "    BIG_PATCH_SHAPE,\n",
    "    SEED,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples: 370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((None, None, None, None), (None, None, None, None)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_x = tf.data.Dataset.zip(\n",
    "    (\n",
    "        tfrecord_dataset(SMALL_NEG_TFRECORD),\n",
    "        tfrecord_dataset(BIG_NEG_TFRECORD),\n",
    "    )\n",
    ")\n",
    "num_neg_samples = sum(1 for _ in neg_x)\n",
    "print(f\"Number of negative samples: {num_neg_samples}\")\n",
    "neg_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_dataset = tf.data.Dataset.zip(\n",
    "    (neg_x, tf.data.Dataset.from_tensor_slices(np.int8([[0]])).repeat(num_neg_samples))\n",
    ")\n",
    "assert sum(1 for _ in neg_dataset) == num_neg_samples\n",
    "neg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples: 379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((None, None, None, None), (None, None, None, None)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x = tf.data.Dataset.zip(\n",
    "    (\n",
    "        tfrecord_dataset(SMALL_POS_TFRECORD),\n",
    "        tfrecord_dataset(BIG_POS_TFRECORD),\n",
    "    )\n",
    ")\n",
    "num_pos_samples = sum(1 for _ in pos_x)\n",
    "print(f\"Number of positive samples: {num_pos_samples}\")\n",
    "pos_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dataset = tf.data.Dataset.zip(\n",
    "    (pos_x, tf.data.Dataset.from_tensor_slices(np.int8([[1]])).repeat(num_pos_samples))\n",
    ")\n",
    "assert sum(1 for _ in pos_dataset) == num_pos_samples\n",
    "pos_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_samples = num_neg_samples + num_pos_samples\n",
    "dataset = neg_dataset.concatenate(pos_dataset).shuffle(\n",
    "    buffer_size=total_samples, seed=SEED, reshuffle_each_iteration=False\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "val_perc = 0.1\n",
    "k = 10\n",
    "patience = 30\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "dropout_rate = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "    input_small = keras.Input(SMALL_PATCH_SHAPE, name=\"input_small\")\n",
    "    x_small = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_small_1\",\n",
    "    )(input_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"maxpool_small_1\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_small_2\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"maxpool_small_2\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_small_3\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"maxpool_small_3\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_small_4\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.Flatten(name=\"flatten_small\")(x_small)\n",
    "\n",
    "    input_big = keras.Input(BIG_PATCH_SHAPE, name=\"input_big\")\n",
    "    x_big = keras.layers.MaxPooling3D((2, 2, 2), name=\"maxpool_big_0\")(input_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_big_1\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"maxpool_big_1\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_big_2\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"maxpool_big_2\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_big_3\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"maxpool_big_3\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"selu_conv3d_big_4\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.Flatten(name=\"flatten_big\")(x_big)\n",
    "\n",
    "    x = keras.layers.concatenate([x_small, x_big], name=\"concatenate\")\n",
    "    x = SeluDense(128, name=\"selu_dense\")(x)\n",
    "    x = keras.layers.AlphaDropout(dropout_rate, name=\"alpha_dropout\")(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\")(x)\n",
    "\n",
    "    cnn = keras.Model(inputs=[input_small, input_big], outputs=x, name=\"3dcnn\")\n",
    "\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.TruePositives(name=\"tp\"),\n",
    "            keras.metrics.FalsePositives(name=\"fp\"),\n",
    "            keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "            keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.662162184715271,\n",
      " 'fn': 9.0,\n",
      " 'fp': 16.0,\n",
      " 'loss': 0.5848488807678223,\n",
      " 'tn': 17.0,\n",
      " 'tp': 32.0}\n",
      "{'accuracy': 0.7297297120094299,\n",
      " 'fn': 17.0,\n",
      " 'fp': 3.0,\n",
      " 'loss': 0.8103933334350586,\n",
      " 'tn': 36.0,\n",
      " 'tp': 18.0}\n",
      "{'accuracy': 0.5405405163764954,\n",
      " 'fn': 6.0,\n",
      " 'fp': 28.0,\n",
      " 'loss': 0.9122430086135864,\n",
      " 'tn': 10.0,\n",
      " 'tp': 30.0}\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.0272s). Check your callbacks.\n",
      "{'accuracy': 0.6351351141929626,\n",
      " 'fn': 23.0,\n",
      " 'fp': 4.0,\n",
      " 'loss': 1.1534898281097412,\n",
      " 'tn': 33.0,\n",
      " 'tp': 14.0}\n",
      "{'accuracy': 0.6081081032752991,\n",
      " 'fn': 1.0,\n",
      " 'fp': 28.0,\n",
      " 'loss': 0.9350642561912537,\n",
      " 'tn': 8.0,\n",
      " 'tp': 37.0}\n",
      "{'accuracy': 0.5945945978164673,\n",
      " 'fn': 8.0,\n",
      " 'fp': 22.0,\n",
      " 'loss': 0.7179050445556641,\n",
      " 'tn': 14.0,\n",
      " 'tp': 30.0}\n",
      "{'accuracy': 0.5135135054588318,\n",
      " 'fn': 2.0,\n",
      " 'fp': 34.0,\n",
      " 'loss': 1.3297961950302124,\n",
      " 'tn': 8.0,\n",
      " 'tp': 30.0}\n",
      "{'accuracy': 0.5675675868988037,\n",
      " 'fn': 2.0,\n",
      " 'fp': 30.0,\n",
      " 'loss': 0.8512935042381287,\n",
      " 'tn': 1.0,\n",
      " 'tp': 41.0}\n",
      "{'accuracy': 0.5405405163764954,\n",
      " 'fn': 33.0,\n",
      " 'fp': 1.0,\n",
      " 'loss': 1.781236171722412,\n",
      " 'tn': 35.0,\n",
      " 'tp': 5.0}\n",
      "{'accuracy': 0.6351351141929626,\n",
      " 'fn': 7.0,\n",
      " 'fp': 20.0,\n",
      " 'loss': 0.7551336288452148,\n",
      " 'tn': 17.0,\n",
      " 'tp': 30.0}\n",
      "{'accuracy': 0.6027026951313019, 'fn': 10.8, 'fp': 18.6, 'tn': 17.9, 'tp': 26.7}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\"tp\": [], \"fp\": [], \"tn\": [], \"fn\": [], \"accuracy\": []}\n",
    "for train_val_dataset, test_dataset in kfolds(k, dataset, cardinality=total_samples):\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "    train_dataset, val_dataset = train_test_split(train_val_dataset, test_perc=val_perc)\n",
    "    val_dataset = val_dataset.batch(1)\n",
    "    train_dataset = (\n",
    "        train_dataset.batch(batch_size)\n",
    "        .cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=128, reshuffle_each_iteration=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    cnn = build_and_compile_model()\n",
    "    start_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_fname = f\"models/baseline-{start_time}.h5\"\n",
    "    log_dir = f\"logs/baseline-{start_time}\"\n",
    "    cnn = train_model(\n",
    "        cnn, train_dataset, val_dataset, patience, \"val_accuracy\", model_fname, log_dir,\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    pprint(test_metrics)\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        if metric_name in metrics:\n",
    "            metrics[metric_name].append(metric_value)\n",
    "mean_metrics = {\n",
    "    metric_name: mean(metric_values)\n",
    "    for metric_name, metric_values in metrics.items()\n",
    "    if metric_name in metrics\n",
    "}\n",
    "pprint(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches, label = next(iter(test_dataset.skip(6)))\n",
    "print(f\"label: {label[0][0].numpy()}\")\n",
    "prediction = cnn(patches, training=False)\n",
    "print(f\"prediction: {prediction[0][0].numpy()}\")\n",
    "plot_volume_animation(patches[0][0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

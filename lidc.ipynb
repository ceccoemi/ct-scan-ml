{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import classification_dataset, kfolds, train_test_split\n",
    "from train import train_model, train_model_with_early_stopping\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from plot import plot_slice, plot_volume_animation\n",
    "from config import (\n",
    "    LIDC_SMALL_NEG_TFRECORD,\n",
    "    LIDC_BIG_NEG_TFRECORD,\n",
    "    LIDC_SMALL_POS_TFRECORD,\n",
    "    LIDC_BIG_POS_TFRECORD,\n",
    "    SMALL_PATCH_SHAPE,\n",
    "    BIG_PATCH_SHAPE,\n",
    "    SEED,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_3d_cnn():\n",
    "    input_small = keras.Input(SMALL_PATCH_SHAPE, name=\"input_small\")\n",
    "    x_small = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_1\",\n",
    "    )(input_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"small_maxpool_1\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_2\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"small_maxpool_2\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_3\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"small_maxpool_3\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_4\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.Flatten(name=\"flatten_small\")(x_small)\n",
    "\n",
    "    input_big = keras.Input(BIG_PATCH_SHAPE, name=\"input_big\")\n",
    "    x_big = keras.layers.MaxPooling3D((2, 2, 2), name=\"big_maxpool_0\")(input_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_1\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"big_maxpool_1\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_2\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"big_maxpool_2\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_3\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"big_maxpool_3\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_4\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.Flatten(name=\"flatten_big\")(x_big)\n",
    "\n",
    "    x = keras.layers.concatenate([x_small, x_big], name=\"concatenate\")\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\")(x)\n",
    "\n",
    "    cnn_3d = keras.Model(inputs=[input_small, input_big], outputs=x, name=\"3dcnn\")\n",
    "\n",
    "    return cnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, samples = classification_dataset(\n",
    "    LIDC_SMALL_NEG_TFRECORD,\n",
    "    LIDC_BIG_NEG_TFRECORD,\n",
    "    LIDC_SMALL_POS_TFRECORD,\n",
    "    LIDC_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perc = 0.1\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (((None, None, None, None, None), (None, None, None, None, None)), (None, 1)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset = train_test_split(\n",
    "    dataset, test_perc=val_perc, cardinality=samples\n",
    ")\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = (\n",
    "    train_dataset.cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "patience = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18274, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18274 to 0.16303, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16303 to 0.15106, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15106 to 0.14526, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14526\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14526 to 0.13689, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.13689 to 0.13687, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.13687 to 0.13308, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13308 to 0.12953, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.12953 to 0.12910, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12910\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12910 to 0.12499, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12499 to 0.12351, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12351 to 0.12289, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.12289 to 0.12084, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12084 to 0.12049, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12049\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.12049\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.12049\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.12049 to 0.11837, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.11837 to 0.11744, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11744\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11744\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11744 to 0.11407, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11407\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11407\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11407\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11407\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11407 to 0.11367, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11367 to 0.11352, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11352\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11352\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11352\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11352 to 0.11309, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11309\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11309 to 0.11253, saving model to models/lidc-3dcnn.h5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11253\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11253\n"
     ]
    }
   ],
   "source": [
    "cnn = build_3d_cnn()\n",
    "cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "        keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model_fname = f\"models/lidc-3dcnn.h5\"\n",
    "log_dir = f\"logs/lidc-3dcnn\"\n",
    "cnn = train_model_with_early_stopping(\n",
    "    cnn,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    patience,\n",
    "    \"val_loss\",\n",
    "    model_fname,\n",
    "    log_dir,\n",
    "    verbose_checkpoint=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

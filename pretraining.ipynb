{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from data import classification_dataset, train_test_split, kfolds\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from plot import plot_slice, plot_volume_animation\n",
    "from config import (\n",
    "    LIDC_SMALL_NEG_TFRECORD,\n",
    "    LIDC_BIG_NEG_TFRECORD,\n",
    "    LIDC_SMALL_POS_TFRECORD,\n",
    "    LIDC_BIG_POS_TFRECORD,\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    SMALL_PATCH_SHAPE,\n",
    "    BIG_PATCH_SHAPE,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lidc_samples = 754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidc_dataset, lidc_samples = classification_dataset(\n",
    "    LIDC_SMALL_NEG_TFRECORD,\n",
    "    LIDC_BIG_NEG_TFRECORD,\n",
    "    LIDC_SMALL_POS_TFRECORD,\n",
    "    LIDC_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "print(f\"{lidc_samples = }\")\n",
    "lidc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_3d_cnn(dropout_rate=0.0):\n",
    "    input_small = keras.Input(SMALL_PATCH_SHAPE, name=\"input_small\")\n",
    "    x_small = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_1\",\n",
    "    )(input_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_1\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_2\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_2\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_3\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_3\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_4\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 1, 2), name=\"small_maxpool_4\")(x_small)\n",
    "    x_small = keras.layers.Flatten(name=\"flatten_small\")(x_small)\n",
    "\n",
    "    input_big = keras.Input(BIG_PATCH_SHAPE, name=\"input_big\")\n",
    "    x_big = keras.layers.MaxPool3D((2, 2, 2), name=\"big_maxpool_0\")(input_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_1\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_1\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_2\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_2\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_3\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_3\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_4\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 1, 2), name=\"big_maxpool_4\")(x_big)\n",
    "    x_big = keras.layers.Flatten(name=\"flatten_big\")(x_big)\n",
    "\n",
    "    x = keras.layers.concatenate([x_small, x_big], name=\"concatenate\")\n",
    "    #x = SeluDense(128, name=\"selu_dense\")(x)\n",
    "    #x = keras.layers.AlphaDropout(dropout_rate)(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\")(x)\n",
    "\n",
    "    cnn_3d = keras.Model(inputs=[input_small, input_big], outputs=x, name=\"3dcnn\")\n",
    "\n",
    "    return cnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "val_perc = 0.1\n",
    "patience = 30\n",
    "batch_size = 16\n",
    "dropout_rate = 0.5\n",
    "metrics = [\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(\n",
    "    lidc_dataset, test_perc=val_perc, seed=SEED\n",
    ")\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = (\n",
    "    train_dataset.cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "cnn = build_3d_cnn(dropout_rate)\n",
    "cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "cnn.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1000,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"models/lidc-3d-cnn.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(val_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spie_samples = 73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spie_dataset, spie_samples = classification_dataset(\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "print(f\"{spie_samples = }\")\n",
    "spie_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3196 - auc: 0.6764 - accuracy: 0.5890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.31961071491241455,\n",
       " 'auc': 0.6764264702796936,\n",
       " 'accuracy': 0.5890411138534546}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "cnn.evaluate(spie_dataset.batch(1), return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pretrained_3d_cnn():\n",
    "    pretrained_3d_cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "    #for layer in pretrained_3d_cnn.layers:\n",
    "    #    if \"conv\" in layer.name:\n",
    "    #        layer.trainable = False\n",
    "    return pretrained_3d_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "learning_rate = 1e-5\n",
    "val_perc = 0.1\n",
    "patience = 30\n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "dropout_rate = 0.5\n",
    "metrics = [\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7908ad8945fe43e18c600fd74e755d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== fold_id = 0 ===================\n",
      "Train size: 45\n",
      "Validation size: 4\n",
      "Test size: 24\n",
      "\n",
      "LIDC training only: \n",
      "loss: 0.274137407541275\n",
      "auc: 0.7777777910232544\n",
      "accuracy: 0.625\n",
      "\n",
      "Without pretraining: \n",
      "loss: 0.19191725552082062\n",
      "auc: 0.788194477558136\n",
      "accuracy: 0.7916666865348816\n",
      "\n",
      "With pretraining: \n",
      "loss: 0.20678023993968964\n",
      "auc: 0.7777778506278992\n",
      "accuracy: 0.75\n",
      "================== fold_id = 1 ===================\n",
      "Train size: 45\n",
      "Validation size: 4\n",
      "Test size: 24\n",
      "\n",
      "LIDC training only: \n",
      "loss: 0.28158077597618103\n",
      "auc: 0.7027972340583801\n",
      "accuracy: 0.6666666865348816\n",
      "\n",
      "Without pretraining: \n",
      "loss: 0.2362479418516159\n",
      "auc: 0.6608391404151917\n",
      "accuracy: 0.5833333134651184\n",
      "\n",
      "With pretraining: \n",
      "loss: 0.1781003326177597\n",
      "auc: 0.8391607999801636\n",
      "accuracy: 0.7083333134651184\n",
      "================== fold_id = 2 ===================\n",
      "Train size: 44\n",
      "Validation size: 4\n",
      "Test size: 25\n",
      "\n",
      "LIDC training only: \n",
      "loss: 0.39977383613586426\n",
      "auc: 0.58441561460495\n",
      "accuracy: 0.47999998927116394\n",
      "\n",
      "Without pretraining: \n",
      "loss: 0.4054909944534302\n",
      "auc: 0.5681818127632141\n",
      "accuracy: 0.47999998927116394\n",
      "\n",
      "With pretraining: \n",
      "loss: 0.3125009834766388\n",
      "auc: 0.5779220461845398\n",
      "accuracy: 0.5600000023841858\n",
      "\n",
      "==================== average =====================\n",
      "LIDC training only: \n",
      "auc: 0.6883302330970764\n",
      "accuracy: 0.5905556082725525\n",
      "\n",
      "Without pretraining: \n",
      "auc: 0.6724051833152771\n",
      "accuracy: 0.6183333396911621\n",
      "\n",
      "With pretraining: \n",
      "auc: 0.7316202521324158\n",
      "accuracy: 0.6727777123451233\n"
     ]
    }
   ],
   "source": [
    "lidc_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "wo_pt_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "w_pt_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "fold_id = 0\n",
    "for trainval_dataset, test_dataset in tqdm(\n",
    "    kfolds(k, spie_dataset, cardinality=spie_samples, seed=6), total=k\n",
    "):\n",
    "    print(f\" {fold_id = } \".center(50, \"=\"))\n",
    "\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    train_dataset, val_dataset = train_test_split(trainval_dataset, test_perc=val_perc)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    train_dataset = (\n",
    "        train_dataset.cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    print(f\"Train size: {sum(1 for _ in train_dataset.unbatch())}\")\n",
    "    print(f\"Validation size: {sum(1 for _ in val_dataset.unbatch())}\")\n",
    "    print(f\"Test size: {sum(1 for _ in test_dataset.unbatch())}\")\n",
    "    print()\n",
    "\n",
    "    cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"LIDC training only: \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in lidc_mean_metrics:\n",
    "            lidc_mean_metrics[metric_name].update_state(metric_value)\n",
    "    print(\"\")\n",
    "\n",
    "    cnn = build_3d_cnn(dropout_rate)\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=num_epochs,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"Without pretraining: \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in wo_pt_mean_metrics:\n",
    "            wo_pt_mean_metrics[metric_name].update_state(metric_value)\n",
    "    print(\"\")\n",
    "\n",
    "    cnn = build_pretrained_3d_cnn()\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=num_epochs,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"With pretraining: \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in w_pt_mean_metrics:\n",
    "            w_pt_mean_metrics[metric_name].update_state(metric_value)\n",
    "    fold_id += 1\n",
    "\n",
    "print(\" average \".center(50, \"=\"))\n",
    "print(\"LIDC training only: \")\n",
    "for metric_name, metric_value in lidc_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")\n",
    "print(\"\")\n",
    "print(\"Without pretraining: \")\n",
    "for metric_name, metric_value in wo_pt_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"With pretraining: \")\n",
    "for metric_name, metric_value in w_pt_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

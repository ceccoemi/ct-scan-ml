{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from data import classification_dataset, train_test_split, kfolds\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from callbacks import TimeEpoch\n",
    "from plot import plot_slice, plot_volume_animation, plot_loss_history\n",
    "from config import (\n",
    "    LIDC_SMALL_NEG_TFRECORD,\n",
    "    LIDC_BIG_NEG_TFRECORD,\n",
    "    LIDC_SMALL_POS_TFRECORD,\n",
    "    LIDC_BIG_POS_TFRECORD,\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    SMALL_PATCH_SHAPE,\n",
    "    BIG_PATCH_SHAPE,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lidc_samples = 754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidc_dataset, lidc_samples = classification_dataset(\n",
    "    LIDC_SMALL_NEG_TFRECORD,\n",
    "    LIDC_BIG_NEG_TFRECORD,\n",
    "    LIDC_SMALL_POS_TFRECORD,\n",
    "    LIDC_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "print(f\"{lidc_samples = }\")\n",
    "lidc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_3d_cnn():\n",
    "    input_small = keras.Input(SMALL_PATCH_SHAPE, name=\"input_small\")\n",
    "    x_small = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_1\",\n",
    "    )(input_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_1\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_2\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_2\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_3\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_3\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_4\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPool3D((1, 2, 2), name=\"small_maxpool_4\")(x_small)\n",
    "    x_small = keras.layers.Flatten(name=\"flatten_small\")(x_small)\n",
    "\n",
    "    input_big = keras.Input(BIG_PATCH_SHAPE, name=\"input_big\")\n",
    "    x_big = keras.layers.MaxPool3D((2, 2, 2), name=\"big_maxpool_0\")(input_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_1\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_1\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_2\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_2\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_3\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_3\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_4\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPool3D((1, 2, 2), name=\"big_maxpool_4\")(x_big)\n",
    "    x_big = keras.layers.Flatten(name=\"flatten_big\")(x_big)\n",
    "\n",
    "    x = keras.layers.concatenate([x_small, x_big], name=\"concatenate\")\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\")(x)\n",
    "\n",
    "    cnn_3d = keras.Model(inputs=[input_small, input_big], outputs=x, name=\"3dcnn\")\n",
    "\n",
    "    return cnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "val_perc = 0.2\n",
    "patience = 20\n",
    "batch_size = 16\n",
    "metrics = [\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(lidc_dataset, test_perc=val_perc)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = (\n",
    "    train_dataset.cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "     38/Unknown - 1s 18ms/step - loss: 0.6853 - tp: 198.0000 - fp: 172.0000 - tn: 129.0000 - fn: 105.0000 - precision: 0.5351 - recall: 0.6535 - auc: 0.5811 - accuracy: 0.5414\n",
      "Epoch 00001: val_loss improved from inf to 0.62920, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.6853 - tp: 198.0000 - fp: 172.0000 - tn: 129.0000 - fn: 105.0000 - precision: 0.5351 - recall: 0.6535 - auc: 0.5811 - accuracy: 0.5414 - val_loss: 0.6292 - val_tp: 46.0000 - val_fp: 19.0000 - val_tn: 55.0000 - val_fn: 30.0000 - val_precision: 0.7077 - val_recall: 0.6053 - val_auc: 0.7296 - val_accuracy: 0.6733\n",
      "Epoch 2/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.5840 - tp: 205.0000 - fp: 76.0000 - tn: 201.0000 - fn: 78.0000 - precision: 0.7295 - recall: 0.7244 - auc: 0.7950 - accuracy: 0.7250\n",
      "Epoch 00002: val_loss improved from 0.62920 to 0.61725, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.5943 - tp: 219.0000 - fp: 88.0000 - tn: 213.0000 - fn: 84.0000 - precision: 0.7134 - recall: 0.7228 - auc: 0.7806 - accuracy: 0.7152 - val_loss: 0.6172 - val_tp: 60.0000 - val_fp: 38.0000 - val_tn: 36.0000 - val_fn: 16.0000 - val_precision: 0.6122 - val_recall: 0.7895 - val_auc: 0.7392 - val_accuracy: 0.6400\n",
      "Epoch 3/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.5575 - tp: 219.0000 - fp: 83.0000 - tn: 211.0000 - fn: 79.0000 - precision: 0.7252 - recall: 0.7349 - auc: 0.7997 - accuracy: 0.7264\n",
      "Epoch 00003: val_loss improved from 0.61725 to 0.56209, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.5574 - tp: 223.0000 - fp: 86.0000 - tn: 215.0000 - fn: 80.0000 - precision: 0.7217 - recall: 0.7360 - auc: 0.7999 - accuracy: 0.7252 - val_loss: 0.5621 - val_tp: 45.0000 - val_fp: 6.0000 - val_tn: 68.0000 - val_fn: 31.0000 - val_precision: 0.8824 - val_recall: 0.5921 - val_auc: 0.7951 - val_accuracy: 0.7533\n",
      "Epoch 4/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.5217 - tp: 207.0000 - fp: 45.0000 - tn: 247.0000 - fn: 93.0000 - precision: 0.8214 - recall: 0.6900 - auc: 0.8374 - accuracy: 0.7669\n",
      "Epoch 00004: val_loss improved from 0.56209 to 0.54775, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.5229 - tp: 208.0000 - fp: 49.0000 - tn: 252.0000 - fn: 95.0000 - precision: 0.8093 - recall: 0.6865 - auc: 0.8357 - accuracy: 0.7616 - val_loss: 0.5477 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 58.0000 - val_fn: 23.0000 - val_precision: 0.7681 - val_recall: 0.6974 - val_auc: 0.8066 - val_accuracy: 0.7400\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4978 - tp: 220.0000 - fp: 46.0000 - tn: 255.0000 - fn: 83.0000 - precision: 0.8271 - recall: 0.7261 - auc: 0.8639 - accuracy: 0.7864\n",
      "Epoch 00005: val_loss improved from 0.54775 to 0.53961, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4978 - tp: 220.0000 - fp: 46.0000 - tn: 255.0000 - fn: 83.0000 - precision: 0.8271 - recall: 0.7261 - auc: 0.8639 - accuracy: 0.7864 - val_loss: 0.5396 - val_tp: 46.0000 - val_fp: 3.0000 - val_tn: 71.0000 - val_fn: 30.0000 - val_precision: 0.9388 - val_recall: 0.6053 - val_auc: 0.8197 - val_accuracy: 0.7800\n",
      "Epoch 6/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4727 - tp: 208.0000 - fp: 35.0000 - tn: 240.0000 - fn: 77.0000 - precision: 0.8560 - recall: 0.7298 - auc: 0.8853 - accuracy: 0.8000\n",
      "Epoch 00006: val_loss improved from 0.53961 to 0.52603, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4788 - tp: 222.0000 - fp: 41.0000 - tn: 260.0000 - fn: 81.0000 - precision: 0.8441 - recall: 0.7327 - auc: 0.8809 - accuracy: 0.7980 - val_loss: 0.5260 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 55.0000 - val_fn: 17.0000 - val_precision: 0.7564 - val_recall: 0.7763 - val_auc: 0.8291 - val_accuracy: 0.7600\n",
      "Epoch 7/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.4612 - tp: 227.0000 - fp: 43.0000 - tn: 252.0000 - fn: 70.0000 - precision: 0.8407 - recall: 0.7643 - auc: 0.8983 - accuracy: 0.8091\n",
      "Epoch 00007: val_loss improved from 0.52603 to 0.52117, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4611 - tp: 230.0000 - fp: 44.0000 - tn: 257.0000 - fn: 73.0000 - precision: 0.8394 - recall: 0.7591 - auc: 0.8979 - accuracy: 0.8063 - val_loss: 0.5212 - val_tp: 44.0000 - val_fp: 2.0000 - val_tn: 72.0000 - val_fn: 32.0000 - val_precision: 0.9565 - val_recall: 0.5789 - val_auc: 0.8359 - val_accuracy: 0.7733\n",
      "Epoch 8/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4397 - tp: 220.0000 - fp: 29.0000 - tn: 259.0000 - fn: 68.0000 - precision: 0.8835 - recall: 0.7639 - auc: 0.9159 - accuracy: 0.8316\n",
      "Epoch 00008: val_loss improved from 0.52117 to 0.50581, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.4433 - tp: 227.0000 - fp: 29.0000 - tn: 272.0000 - fn: 76.0000 - precision: 0.8867 - recall: 0.7492 - auc: 0.9100 - accuracy: 0.8262 - val_loss: 0.5058 - val_tp: 49.0000 - val_fp: 7.0000 - val_tn: 67.0000 - val_fn: 27.0000 - val_precision: 0.8750 - val_recall: 0.6447 - val_auc: 0.8470 - val_accuracy: 0.7733\n",
      "Epoch 9/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4307 - tp: 225.0000 - fp: 33.0000 - tn: 241.0000 - fn: 61.0000 - precision: 0.8721 - recall: 0.7867 - auc: 0.9195 - accuracy: 0.8321\n",
      "Epoch 00009: val_loss improved from 0.50581 to 0.49950, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.4323 - tp: 239.0000 - fp: 37.0000 - tn: 264.0000 - fn: 64.0000 - precision: 0.8659 - recall: 0.7888 - auc: 0.9180 - accuracy: 0.8328 - val_loss: 0.4995 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 21.0000 - val_precision: 0.8088 - val_recall: 0.7237 - val_auc: 0.8495 - val_accuracy: 0.7733\n",
      "Epoch 10/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4156 - tp: 236.0000 - fp: 34.0000 - tn: 248.0000 - fn: 58.0000 - precision: 0.8741 - recall: 0.8027 - auc: 0.9249 - accuracy: 0.8403\n",
      "Epoch 00010: val_loss improved from 0.49950 to 0.48929, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.4154 - tp: 242.0000 - fp: 35.0000 - tn: 266.0000 - fn: 61.0000 - precision: 0.8736 - recall: 0.7987 - auc: 0.9253 - accuracy: 0.8411 - val_loss: 0.4893 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 67.0000 - val_fn: 26.0000 - val_precision: 0.8772 - val_recall: 0.6579 - val_auc: 0.8567 - val_accuracy: 0.7800\n",
      "Epoch 11/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4102 - tp: 239.0000 - fp: 35.0000 - tn: 253.0000 - fn: 49.0000 - precision: 0.8723 - recall: 0.8299 - auc: 0.9277 - accuracy: 0.8542\n",
      "Epoch 00011: val_loss did not improve from 0.48929\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.4098 - tp: 249.0000 - fp: 36.0000 - tn: 265.0000 - fn: 54.0000 - precision: 0.8737 - recall: 0.8218 - auc: 0.9271 - accuracy: 0.8510 - val_loss: 0.5056 - val_tp: 43.0000 - val_fp: 2.0000 - val_tn: 72.0000 - val_fn: 33.0000 - val_precision: 0.9556 - val_recall: 0.5658 - val_auc: 0.8546 - val_accuracy: 0.7667\n",
      "Epoch 12/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.4069 - tp: 231.0000 - fp: 42.0000 - tn: 254.0000 - fn: 65.0000 - precision: 0.8462 - recall: 0.7804 - auc: 0.9160 - accuracy: 0.8193\n",
      "Epoch 00012: val_loss did not improve from 0.48929\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.4044 - tp: 237.0000 - fp: 42.0000 - tn: 259.0000 - fn: 66.0000 - precision: 0.8495 - recall: 0.7822 - auc: 0.9173 - accuracy: 0.8212 - val_loss: 0.4925 - val_tp: 44.0000 - val_fp: 6.0000 - val_tn: 68.0000 - val_fn: 32.0000 - val_precision: 0.8800 - val_recall: 0.5789 - val_auc: 0.8597 - val_accuracy: 0.7467\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3851 - tp: 244.0000 - fp: 34.0000 - tn: 267.0000 - fn: 59.0000 - precision: 0.8777 - recall: 0.8053 - auc: 0.9412 - accuracy: 0.8460\n",
      "Epoch 00013: val_loss improved from 0.48929 to 0.47390, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3851 - tp: 244.0000 - fp: 34.0000 - tn: 267.0000 - fn: 59.0000 - precision: 0.8777 - recall: 0.8053 - auc: 0.9412 - accuracy: 0.8460 - val_loss: 0.4739 - val_tp: 59.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 17.0000 - val_precision: 0.8194 - val_recall: 0.7763 - val_auc: 0.8674 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3840 - tp: 251.0000 - fp: 42.0000 - tn: 245.0000 - fn: 38.0000 - precision: 0.8567 - recall: 0.8685 - auc: 0.9368 - accuracy: 0.8611\n",
      "Epoch 00014: val_loss did not improve from 0.47390\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.3792 - tp: 263.0000 - fp: 43.0000 - tn: 258.0000 - fn: 40.0000 - precision: 0.8595 - recall: 0.8680 - auc: 0.9385 - accuracy: 0.8626 - val_loss: 0.5281 - val_tp: 40.0000 - val_fp: 2.0000 - val_tn: 72.0000 - val_fn: 36.0000 - val_precision: 0.9524 - val_recall: 0.5263 - val_auc: 0.8538 - val_accuracy: 0.7467\n",
      "Epoch 15/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3859 - tp: 222.0000 - fp: 37.0000 - tn: 250.0000 - fn: 67.0000 - precision: 0.8571 - recall: 0.7682 - auc: 0.9281 - accuracy: 0.8194\n",
      "Epoch 00015: val_loss did not improve from 0.47390\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.3867 - tp: 235.0000 - fp: 40.0000 - tn: 261.0000 - fn: 68.0000 - precision: 0.8545 - recall: 0.7756 - auc: 0.9269 - accuracy: 0.8212 - val_loss: 0.4747 - val_tp: 51.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 25.0000 - val_precision: 0.8226 - val_recall: 0.6711 - val_auc: 0.8656 - val_accuracy: 0.7600\n",
      "Epoch 16/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3672 - tp: 222.0000 - fp: 22.0000 - tn: 255.0000 - fn: 61.0000 - precision: 0.9098 - recall: 0.7845 - auc: 0.9475 - accuracy: 0.8518\n",
      "Epoch 00016: val_loss improved from 0.47390 to 0.47026, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3625 - tp: 241.0000 - fp: 24.0000 - tn: 277.0000 - fn: 62.0000 - precision: 0.9094 - recall: 0.7954 - auc: 0.9502 - accuracy: 0.8576 - val_loss: 0.4703 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 62.0000 - val_fn: 20.0000 - val_precision: 0.8235 - val_recall: 0.7368 - val_auc: 0.8656 - val_accuracy: 0.7867\n",
      "Epoch 17/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.3564 - tp: 244.0000 - fp: 29.0000 - tn: 268.0000 - fn: 51.0000 - precision: 0.8938 - recall: 0.8271 - auc: 0.9475 - accuracy: 0.8649\n",
      "Epoch 00017: val_loss did not improve from 0.47026\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.3597 - tp: 248.0000 - fp: 29.0000 - tn: 272.0000 - fn: 55.0000 - precision: 0.8953 - recall: 0.8185 - auc: 0.9455 - accuracy: 0.8609 - val_loss: 0.4828 - val_tp: 45.0000 - val_fp: 3.0000 - val_tn: 71.0000 - val_fn: 31.0000 - val_precision: 0.9375 - val_recall: 0.5921 - val_auc: 0.8702 - val_accuracy: 0.7733\n",
      "Epoch 18/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.3425 - tp: 257.0000 - fp: 23.0000 - tn: 274.0000 - fn: 38.0000 - precision: 0.9179 - recall: 0.8712 - auc: 0.9577 - accuracy: 0.8970\n",
      "Epoch 00018: val_loss improved from 0.47026 to 0.46699, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3428 - tp: 263.0000 - fp: 23.0000 - tn: 278.0000 - fn: 40.0000 - precision: 0.9196 - recall: 0.8680 - auc: 0.9571 - accuracy: 0.8957 - val_loss: 0.4670 - val_tp: 48.0000 - val_fp: 5.0000 - val_tn: 69.0000 - val_fn: 28.0000 - val_precision: 0.9057 - val_recall: 0.6316 - val_auc: 0.8783 - val_accuracy: 0.7800\n",
      "Epoch 19/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.3369 - tp: 258.0000 - fp: 28.0000 - tn: 267.0000 - fn: 39.0000 - precision: 0.9021 - recall: 0.8687 - auc: 0.9628 - accuracy: 0.8868\n",
      "Epoch 00019: val_loss did not improve from 0.46699\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.3353 - tp: 263.0000 - fp: 28.0000 - tn: 273.0000 - fn: 40.0000 - precision: 0.9038 - recall: 0.8680 - auc: 0.9635 - accuracy: 0.8874 - val_loss: 0.4774 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 58.0000 - val_fn: 16.0000 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.8585 - val_accuracy: 0.7867\n",
      "Epoch 20/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3369 - tp: 237.0000 - fp: 20.0000 - tn: 261.0000 - fn: 42.0000 - precision: 0.9222 - recall: 0.8495 - auc: 0.9568 - accuracy: 0.8893\n",
      "Epoch 00020: val_loss improved from 0.46699 to 0.46024, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3349 - tp: 257.0000 - fp: 20.0000 - tn: 281.0000 - fn: 46.0000 - precision: 0.9278 - recall: 0.8482 - auc: 0.9590 - accuracy: 0.8907 - val_loss: 0.4602 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 17.0000 - val_precision: 0.8082 - val_recall: 0.7763 - val_auc: 0.8699 - val_accuracy: 0.7933\n",
      "Epoch 21/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3293 - tp: 248.0000 - fp: 30.0000 - tn: 250.0000 - fn: 32.0000 - precision: 0.8921 - recall: 0.8857 - auc: 0.9581 - accuracy: 0.8893\n",
      "Epoch 00021: val_loss improved from 0.46024 to 0.46015, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.3224 - tp: 271.0000 - fp: 30.0000 - tn: 271.0000 - fn: 32.0000 - precision: 0.9003 - recall: 0.8944 - auc: 0.9619 - accuracy: 0.8974 - val_loss: 0.4602 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 64.0000 - val_fn: 26.0000 - val_precision: 0.8333 - val_recall: 0.6579 - val_auc: 0.8746 - val_accuracy: 0.7600\n",
      "Epoch 22/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3160 - tp: 248.0000 - fp: 24.0000 - tn: 264.0000 - fn: 40.0000 - precision: 0.9118 - recall: 0.8611 - auc: 0.9658 - accuracy: 0.8889\n",
      "Epoch 00022: val_loss improved from 0.46015 to 0.45656, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3182 - tp: 260.0000 - fp: 25.0000 - tn: 276.0000 - fn: 43.0000 - precision: 0.9123 - recall: 0.8581 - auc: 0.9656 - accuracy: 0.8874 - val_loss: 0.4566 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 62.0000 - val_fn: 21.0000 - val_precision: 0.8209 - val_recall: 0.7237 - val_auc: 0.8729 - val_accuracy: 0.7800\n",
      "Epoch 23/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3217 - tp: 249.0000 - fp: 25.0000 - tn: 250.0000 - fn: 36.0000 - precision: 0.9088 - recall: 0.8737 - auc: 0.9694 - accuracy: 0.8911\n",
      "Epoch 00023: val_loss improved from 0.45656 to 0.44763, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3124 - tp: 266.0000 - fp: 26.0000 - tn: 275.0000 - fn: 37.0000 - precision: 0.9110 - recall: 0.8779 - auc: 0.9724 - accuracy: 0.8957 - val_loss: 0.4476 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 62.0000 - val_fn: 22.0000 - val_precision: 0.8182 - val_recall: 0.7105 - val_auc: 0.8801 - val_accuracy: 0.7733\n",
      "Epoch 24/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3028 - tp: 244.0000 - fp: 24.0000 - tn: 259.0000 - fn: 33.0000 - precision: 0.9104 - recall: 0.8809 - auc: 0.9737 - accuracy: 0.8982\n",
      "Epoch 00024: val_loss did not improve from 0.44763\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2991 - tp: 269.0000 - fp: 24.0000 - tn: 277.0000 - fn: 34.0000 - precision: 0.9181 - recall: 0.8878 - auc: 0.9758 - accuracy: 0.9040 - val_loss: 0.4520 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 19.0000 - val_precision: 0.8143 - val_recall: 0.7500 - val_auc: 0.8739 - val_accuracy: 0.7867\n",
      "Epoch 25/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2938 - tp: 267.0000 - fp: 19.0000 - tn: 276.0000 - fn: 30.0000 - precision: 0.9336 - recall: 0.8990 - auc: 0.9774 - accuracy: 0.9172\n",
      "Epoch 00025: val_loss improved from 0.44763 to 0.44170, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2931 - tp: 273.0000 - fp: 20.0000 - tn: 281.0000 - fn: 30.0000 - precision: 0.9317 - recall: 0.9010 - auc: 0.9777 - accuracy: 0.9172 - val_loss: 0.4417 - val_tp: 54.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 22.0000 - val_precision: 0.8308 - val_recall: 0.7105 - val_auc: 0.8840 - val_accuracy: 0.7800\n",
      "Epoch 26/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2868 - tp: 271.0000 - fp: 17.0000 - tn: 278.0000 - fn: 26.0000 - precision: 0.9410 - recall: 0.9125 - auc: 0.9807 - accuracy: 0.9274\n",
      "Epoch 00026: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.2892 - tp: 277.0000 - fp: 19.0000 - tn: 282.0000 - fn: 26.0000 - precision: 0.9358 - recall: 0.9142 - auc: 0.9787 - accuracy: 0.9255 - val_loss: 0.4439 - val_tp: 55.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 21.0000 - val_precision: 0.8333 - val_recall: 0.7237 - val_auc: 0.8791 - val_accuracy: 0.7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2930 - tp: 254.0000 - fp: 17.0000 - tn: 279.0000 - fn: 42.0000 - precision: 0.9373 - recall: 0.8581 - auc: 0.9721 - accuracy: 0.9003\n",
      "Epoch 00027: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.2906 - tp: 261.0000 - fp: 17.0000 - tn: 284.0000 - fn: 42.0000 - precision: 0.9388 - recall: 0.8614 - auc: 0.9730 - accuracy: 0.9023 - val_loss: 0.4715 - val_tp: 63.0000 - val_fp: 18.0000 - val_tn: 56.0000 - val_fn: 13.0000 - val_precision: 0.7778 - val_recall: 0.8289 - val_auc: 0.8611 - val_accuracy: 0.7933\n",
      "Epoch 28/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.2850 - tp: 265.0000 - fp: 27.0000 - tn: 258.0000 - fn: 26.0000 - precision: 0.9075 - recall: 0.9107 - auc: 0.9763 - accuracy: 0.9080\n",
      "Epoch 00028: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2813 - tp: 277.0000 - fp: 27.0000 - tn: 274.0000 - fn: 26.0000 - precision: 0.9112 - recall: 0.9142 - auc: 0.9778 - accuracy: 0.9123 - val_loss: 0.4710 - val_tp: 44.0000 - val_fp: 4.0000 - val_tn: 70.0000 - val_fn: 32.0000 - val_precision: 0.9167 - val_recall: 0.5789 - val_auc: 0.8832 - val_accuracy: 0.7600\n",
      "Epoch 29/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.2842 - tp: 242.0000 - fp: 22.0000 - tn: 259.0000 - fn: 37.0000 - precision: 0.9167 - recall: 0.8674 - auc: 0.9753 - accuracy: 0.8946\n",
      "Epoch 00029: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2793 - tp: 266.0000 - fp: 23.0000 - tn: 278.0000 - fn: 37.0000 - precision: 0.9204 - recall: 0.8779 - auc: 0.9766 - accuracy: 0.9007 - val_loss: 0.4555 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 56.0000 - val_fn: 16.0000 - val_precision: 0.7692 - val_recall: 0.7895 - val_auc: 0.8710 - val_accuracy: 0.7733\n",
      "Epoch 30/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2700 - tp: 268.0000 - fp: 18.0000 - tn: 277.0000 - fn: 29.0000 - precision: 0.9371 - recall: 0.9024 - auc: 0.9824 - accuracy: 0.9206\n",
      "Epoch 00030: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2683 - tp: 274.0000 - fp: 18.0000 - tn: 283.0000 - fn: 29.0000 - precision: 0.9384 - recall: 0.9043 - auc: 0.9830 - accuracy: 0.9222 - val_loss: 0.4441 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 57.0000 - val_fn: 18.0000 - val_precision: 0.7733 - val_recall: 0.7632 - val_auc: 0.8760 - val_accuracy: 0.7667\n",
      "Epoch 31/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2663 - tp: 265.0000 - fp: 14.0000 - tn: 281.0000 - fn: 32.0000 - precision: 0.9498 - recall: 0.8923 - auc: 0.9842 - accuracy: 0.9223\n",
      "Epoch 00031: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2656 - tp: 271.0000 - fp: 15.0000 - tn: 286.0000 - fn: 32.0000 - precision: 0.9476 - recall: 0.8944 - auc: 0.9841 - accuracy: 0.9222 - val_loss: 0.4437 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 56.0000 - val_fn: 16.0000 - val_precision: 0.7692 - val_recall: 0.7895 - val_auc: 0.8772 - val_accuracy: 0.7733\n",
      "Epoch 32/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2561 - tp: 270.0000 - fp: 20.0000 - tn: 277.0000 - fn: 25.0000 - precision: 0.9310 - recall: 0.9153 - auc: 0.9855 - accuracy: 0.9240\n",
      "Epoch 00032: val_loss did not improve from 0.44170\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2560 - tp: 278.0000 - fp: 20.0000 - tn: 281.0000 - fn: 25.0000 - precision: 0.9329 - recall: 0.9175 - auc: 0.9856 - accuracy: 0.9255 - val_loss: 0.4471 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 22.0000 - val_precision: 0.7941 - val_recall: 0.7105 - val_auc: 0.8751 - val_accuracy: 0.7600\n",
      "Epoch 33/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2490 - tp: 275.0000 - fp: 17.0000 - tn: 280.0000 - fn: 20.0000 - precision: 0.9418 - recall: 0.9322 - auc: 0.9850 - accuracy: 0.9375\n",
      "Epoch 00033: val_loss improved from 0.44170 to 0.43135, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2491 - tp: 281.0000 - fp: 17.0000 - tn: 284.0000 - fn: 22.0000 - precision: 0.9430 - recall: 0.9274 - auc: 0.9852 - accuracy: 0.9354 - val_loss: 0.4314 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 20.0000 - val_precision: 0.8000 - val_recall: 0.7368 - val_auc: 0.8847 - val_accuracy: 0.7733\n",
      "Epoch 34/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2517 - tp: 276.0000 - fp: 17.0000 - tn: 278.0000 - fn: 21.0000 - precision: 0.9420 - recall: 0.9293 - auc: 0.9850 - accuracy: 0.9358\n",
      "Epoch 00034: val_loss did not improve from 0.43135\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.2521 - tp: 282.0000 - fp: 18.0000 - tn: 283.0000 - fn: 21.0000 - precision: 0.9400 - recall: 0.9307 - auc: 0.9849 - accuracy: 0.9354 - val_loss: 0.4521 - val_tp: 48.0000 - val_fp: 6.0000 - val_tn: 68.0000 - val_fn: 28.0000 - val_precision: 0.8889 - val_recall: 0.6316 - val_auc: 0.8856 - val_accuracy: 0.7733\n",
      "Epoch 35/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.2508 - tp: 256.0000 - fp: 11.0000 - tn: 266.0000 - fn: 27.0000 - precision: 0.9588 - recall: 0.9046 - auc: 0.9869 - accuracy: 0.9321\n",
      "Epoch 00035: val_loss did not improve from 0.43135\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.2511 - tp: 276.0000 - fp: 11.0000 - tn: 290.0000 - fn: 27.0000 - precision: 0.9617 - recall: 0.9109 - auc: 0.9872 - accuracy: 0.9371 - val_loss: 0.4316 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 20.0000 - val_precision: 0.8000 - val_recall: 0.7368 - val_auc: 0.8845 - val_accuracy: 0.7733\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2374 - tp: 284.0000 - fp: 16.0000 - tn: 285.0000 - fn: 19.0000 - precision: 0.9467 - recall: 0.9373 - auc: 0.9886 - accuracy: 0.9421\n",
      "Epoch 00036: val_loss did not improve from 0.43135\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2374 - tp: 284.0000 - fp: 16.0000 - tn: 285.0000 - fn: 19.0000 - precision: 0.9467 - recall: 0.9373 - auc: 0.9886 - accuracy: 0.9421 - val_loss: 0.4385 - val_tp: 51.0000 - val_fp: 7.0000 - val_tn: 67.0000 - val_fn: 25.0000 - val_precision: 0.8793 - val_recall: 0.6711 - val_auc: 0.8880 - val_accuracy: 0.7867\n",
      "Epoch 37/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2374 - tp: 277.0000 - fp: 16.0000 - tn: 278.0000 - fn: 21.0000 - precision: 0.9454 - recall: 0.9295 - auc: 0.9891 - accuracy: 0.9375\n",
      "Epoch 00037: val_loss did not improve from 0.43135\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.2367 - tp: 281.0000 - fp: 16.0000 - tn: 285.0000 - fn: 22.0000 - precision: 0.9461 - recall: 0.9274 - auc: 0.9893 - accuracy: 0.9371 - val_loss: 0.4442 - val_tp: 48.0000 - val_fp: 6.0000 - val_tn: 68.0000 - val_fn: 28.0000 - val_precision: 0.8889 - val_recall: 0.6316 - val_auc: 0.8877 - val_accuracy: 0.7733\n",
      "Epoch 38/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2342 - tp: 277.0000 - fp: 15.0000 - tn: 279.0000 - fn: 21.0000 - precision: 0.9486 - recall: 0.9295 - auc: 0.9882 - accuracy: 0.9392\n",
      "Epoch 00038: val_loss did not improve from 0.43135\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2354 - tp: 282.0000 - fp: 15.0000 - tn: 286.0000 - fn: 21.0000 - precision: 0.9495 - recall: 0.9307 - auc: 0.9882 - accuracy: 0.9404 - val_loss: 0.4351 - val_tp: 51.0000 - val_fp: 8.0000 - val_tn: 66.0000 - val_fn: 25.0000 - val_precision: 0.8644 - val_recall: 0.6711 - val_auc: 0.8873 - val_accuracy: 0.7800\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2283 - tp: 282.0000 - fp: 12.0000 - tn: 289.0000 - fn: 21.0000 - precision: 0.9592 - recall: 0.9307 - auc: 0.9901 - accuracy: 0.9454\n",
      "Epoch 00039: val_loss improved from 0.43135 to 0.43056, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2283 - tp: 282.0000 - fp: 12.0000 - tn: 289.0000 - fn: 21.0000 - precision: 0.9592 - recall: 0.9307 - auc: 0.9901 - accuracy: 0.9454 - val_loss: 0.4306 - val_tp: 54.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 22.0000 - val_precision: 0.7826 - val_recall: 0.7105 - val_auc: 0.8824 - val_accuracy: 0.7533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2229 - tp: 269.0000 - fp: 10.0000 - tn: 288.0000 - fn: 25.0000 - precision: 0.9642 - recall: 0.9150 - auc: 0.9912 - accuracy: 0.9409\n",
      "Epoch 00040: val_loss did not improve from 0.43056\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2220 - tp: 278.0000 - fp: 10.0000 - tn: 291.0000 - fn: 25.0000 - precision: 0.9653 - recall: 0.9175 - auc: 0.9915 - accuracy: 0.9421 - val_loss: 0.4812 - val_tp: 66.0000 - val_fp: 21.0000 - val_tn: 53.0000 - val_fn: 10.0000 - val_precision: 0.7586 - val_recall: 0.8684 - val_auc: 0.8628 - val_accuracy: 0.7933\n",
      "Epoch 41/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.2267 - tp: 266.0000 - fp: 19.0000 - tn: 259.0000 - fn: 16.0000 - precision: 0.9333 - recall: 0.9433 - auc: 0.9870 - accuracy: 0.9375\n",
      "Epoch 00041: val_loss did not improve from 0.43056\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2287 - tp: 283.0000 - fp: 19.0000 - tn: 282.0000 - fn: 20.0000 - precision: 0.9371 - recall: 0.9340 - auc: 0.9867 - accuracy: 0.9354 - val_loss: 0.4632 - val_tp: 44.0000 - val_fp: 5.0000 - val_tn: 69.0000 - val_fn: 32.0000 - val_precision: 0.8980 - val_recall: 0.5789 - val_auc: 0.8858 - val_accuracy: 0.7533\n",
      "Epoch 42/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2149 - tp: 275.0000 - fp: 11.0000 - tn: 284.0000 - fn: 22.0000 - precision: 0.9615 - recall: 0.9259 - auc: 0.9912 - accuracy: 0.9443\n",
      "Epoch 00042: val_loss improved from 0.43056 to 0.42623, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2154 - tp: 280.0000 - fp: 11.0000 - tn: 290.0000 - fn: 23.0000 - precision: 0.9622 - recall: 0.9241 - auc: 0.9913 - accuracy: 0.9437 - val_loss: 0.4262 - val_tp: 52.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 24.0000 - val_precision: 0.8000 - val_recall: 0.6842 - val_auc: 0.8861 - val_accuracy: 0.7533\n",
      "Epoch 43/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2152 - tp: 281.0000 - fp: 12.0000 - tn: 283.0000 - fn: 16.0000 - precision: 0.9590 - recall: 0.9461 - auc: 0.9913 - accuracy: 0.9527\n",
      "Epoch 00043: val_loss did not improve from 0.42623\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.2134 - tp: 287.0000 - fp: 12.0000 - tn: 289.0000 - fn: 16.0000 - precision: 0.9599 - recall: 0.9472 - auc: 0.9916 - accuracy: 0.9536 - val_loss: 0.4399 - val_tp: 49.0000 - val_fp: 6.0000 - val_tn: 68.0000 - val_fn: 27.0000 - val_precision: 0.8909 - val_recall: 0.6447 - val_auc: 0.8890 - val_accuracy: 0.7800\n",
      "Epoch 44/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2045 - tp: 285.0000 - fp: 11.0000 - tn: 283.0000 - fn: 13.0000 - precision: 0.9628 - recall: 0.9564 - auc: 0.9952 - accuracy: 0.9595\n",
      "Epoch 00044: val_loss did not improve from 0.42623\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2045 - tp: 290.0000 - fp: 11.0000 - tn: 290.0000 - fn: 13.0000 - precision: 0.9635 - recall: 0.9571 - auc: 0.9953 - accuracy: 0.9603 - val_loss: 0.4271 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 18.0000 - val_precision: 0.7945 - val_recall: 0.7632 - val_auc: 0.8818 - val_accuracy: 0.7800\n",
      "Epoch 45/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2016 - tp: 288.0000 - fp: 10.0000 - tn: 285.0000 - fn: 9.0000 - precision: 0.9664 - recall: 0.9697 - auc: 0.9946 - accuracy: 0.9679\n",
      "Epoch 00045: val_loss did not improve from 0.42623\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.2011 - tp: 294.0000 - fp: 10.0000 - tn: 291.0000 - fn: 9.0000 - precision: 0.9671 - recall: 0.9703 - auc: 0.9947 - accuracy: 0.9685 - val_loss: 0.4274 - val_tp: 52.0000 - val_fp: 12.0000 - val_tn: 62.0000 - val_fn: 24.0000 - val_precision: 0.8125 - val_recall: 0.6842 - val_auc: 0.8866 - val_accuracy: 0.7600\n",
      "Epoch 46/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.2004 - tp: 277.0000 - fp: 9.0000 - tn: 275.0000 - fn: 15.0000 - precision: 0.9685 - recall: 0.9486 - auc: 0.9953 - accuracy: 0.9583\n",
      "Epoch 00046: val_loss did not improve from 0.42623\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1994 - tp: 288.0000 - fp: 10.0000 - tn: 291.0000 - fn: 15.0000 - precision: 0.9664 - recall: 0.9505 - auc: 0.9952 - accuracy: 0.9586 - val_loss: 0.4317 - val_tp: 52.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 24.0000 - val_precision: 0.7761 - val_recall: 0.6842 - val_auc: 0.8806 - val_accuracy: 0.7400\n",
      "Epoch 47/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.2031 - tp: 262.0000 - fp: 9.0000 - tn: 270.0000 - fn: 19.0000 - precision: 0.9668 - recall: 0.9324 - auc: 0.9927 - accuracy: 0.9500\n",
      "Epoch 00047: val_loss improved from 0.42623 to 0.42474, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2014 - tp: 282.0000 - fp: 9.0000 - tn: 292.0000 - fn: 21.0000 - precision: 0.9691 - recall: 0.9307 - auc: 0.9932 - accuracy: 0.9503 - val_loss: 0.4247 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 20.0000 - val_precision: 0.7887 - val_recall: 0.7368 - val_auc: 0.8834 - val_accuracy: 0.7667\n",
      "Epoch 48/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1928 - tp: 288.0000 - fp: 10.0000 - tn: 287.0000 - fn: 7.0000 - precision: 0.9664 - recall: 0.9763 - auc: 0.9955 - accuracy: 0.9713\n",
      "Epoch 00048: val_loss improved from 0.42474 to 0.41895, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.1925 - tp: 296.0000 - fp: 10.0000 - tn: 291.0000 - fn: 7.0000 - precision: 0.9673 - recall: 0.9769 - auc: 0.9957 - accuracy: 0.9719 - val_loss: 0.4190 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 22.0000 - val_precision: 0.8060 - val_recall: 0.7105 - val_auc: 0.8895 - val_accuracy: 0.7667\n",
      "Epoch 49/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1838 - tp: 290.0000 - fp: 7.0000 - tn: 288.0000 - fn: 7.0000 - precision: 0.9764 - recall: 0.9764 - auc: 0.9973 - accuracy: 0.9764\n",
      "Epoch 00049: val_loss did not improve from 0.41895\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1852 - tp: 295.0000 - fp: 7.0000 - tn: 294.0000 - fn: 8.0000 - precision: 0.9768 - recall: 0.9736 - auc: 0.9971 - accuracy: 0.9752 - val_loss: 0.4209 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 16.0000 - val_precision: 0.8000 - val_recall: 0.7895 - val_auc: 0.8847 - val_accuracy: 0.7933\n",
      "Epoch 50/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1877 - tp: 271.0000 - fp: 14.0000 - tn: 266.0000 - fn: 9.0000 - precision: 0.9509 - recall: 0.9679 - auc: 0.9933 - accuracy: 0.9589\n",
      "Epoch 00050: val_loss did not improve from 0.41895\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1953 - tp: 288.0000 - fp: 14.0000 - tn: 287.0000 - fn: 15.0000 - precision: 0.9536 - recall: 0.9505 - auc: 0.9918 - accuracy: 0.9520 - val_loss: 0.4324 - val_tp: 49.0000 - val_fp: 9.0000 - val_tn: 65.0000 - val_fn: 27.0000 - val_precision: 0.8448 - val_recall: 0.6447 - val_auc: 0.8889 - val_accuracy: 0.7600\n",
      "Epoch 51/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1809 - tp: 290.0000 - fp: 9.0000 - tn: 284.0000 - fn: 9.0000 - precision: 0.9699 - recall: 0.9699 - auc: 0.9967 - accuracy: 0.9696\n",
      "Epoch 00051: val_loss did not improve from 0.41895\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.1811 - tp: 293.0000 - fp: 9.0000 - tn: 292.0000 - fn: 10.0000 - precision: 0.9702 - recall: 0.9670 - auc: 0.9967 - accuracy: 0.9685 - val_loss: 0.4208 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 21.0000 - val_precision: 0.7971 - val_recall: 0.7237 - val_auc: 0.8852 - val_accuracy: 0.7667\n",
      "Epoch 52/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1768 - tp: 292.0000 - fp: 8.0000 - tn: 287.0000 - fn: 5.0000 - precision: 0.9733 - recall: 0.9832 - auc: 0.9974 - accuracy: 0.9780\n",
      "Epoch 00052: val_loss improved from 0.41895 to 0.41877, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.1761 - tp: 298.0000 - fp: 8.0000 - tn: 293.0000 - fn: 5.0000 - precision: 0.9739 - recall: 0.9835 - auc: 0.9975 - accuracy: 0.9785 - val_loss: 0.4188 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 22.0000 - val_precision: 0.7941 - val_recall: 0.7105 - val_auc: 0.8868 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1781 - tp: 287.0000 - fp: 10.0000 - tn: 285.0000 - fn: 10.0000 - precision: 0.9663 - recall: 0.9663 - auc: 0.9947 - accuracy: 0.9662\n",
      "Epoch 00053: val_loss did not improve from 0.41877\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1773 - tp: 293.0000 - fp: 10.0000 - tn: 291.0000 - fn: 10.0000 - precision: 0.9670 - recall: 0.9670 - auc: 0.9948 - accuracy: 0.9669 - val_loss: 0.4279 - val_tp: 51.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 25.0000 - val_precision: 0.8226 - val_recall: 0.6711 - val_auc: 0.8887 - val_accuracy: 0.7600\n",
      "Epoch 54/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1813 - tp: 273.0000 - fp: 10.0000 - tn: 266.0000 - fn: 11.0000 - precision: 0.9647 - recall: 0.9613 - auc: 0.9952 - accuracy: 0.9625\n",
      "Epoch 00054: val_loss improved from 0.41877 to 0.41628, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.1773 - tp: 292.0000 - fp: 10.0000 - tn: 291.0000 - fn: 11.0000 - precision: 0.9669 - recall: 0.9637 - auc: 0.9957 - accuracy: 0.9652 - val_loss: 0.4163 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 21.0000 - val_precision: 0.7971 - val_recall: 0.7237 - val_auc: 0.8905 - val_accuracy: 0.7667\n",
      "Epoch 55/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1688 - tp: 268.0000 - fp: 7.0000 - tn: 278.0000 - fn: 7.0000 - precision: 0.9745 - recall: 0.9745 - auc: 0.9977 - accuracy: 0.9750\n",
      "Epoch 00055: val_loss did not improve from 0.41628\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1696 - tp: 295.0000 - fp: 7.0000 - tn: 294.0000 - fn: 8.0000 - precision: 0.9768 - recall: 0.9736 - auc: 0.9978 - accuracy: 0.9752 - val_loss: 0.4311 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 56.0000 - val_fn: 15.0000 - val_precision: 0.7722 - val_recall: 0.8026 - val_auc: 0.8802 - val_accuracy: 0.7800\n",
      "Epoch 56/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1683 - tp: 283.0000 - fp: 9.0000 - tn: 277.0000 - fn: 7.0000 - precision: 0.9692 - recall: 0.9759 - auc: 0.9963 - accuracy: 0.9722\n",
      "Epoch 00056: val_loss did not improve from 0.41628\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1704 - tp: 295.0000 - fp: 10.0000 - tn: 291.0000 - fn: 8.0000 - precision: 0.9672 - recall: 0.9736 - auc: 0.9962 - accuracy: 0.9702 - val_loss: 0.4187 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 22.0000 - val_precision: 0.7941 - val_recall: 0.7105 - val_auc: 0.8883 - val_accuracy: 0.7600\n",
      "Epoch 57/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1617 - tp: 281.0000 - fp: 4.0000 - tn: 283.0000 - fn: 8.0000 - precision: 0.9860 - recall: 0.9723 - auc: 0.9972 - accuracy: 0.9792 \n",
      "Epoch 00057: val_loss did not improve from 0.41628\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1626 - tp: 294.0000 - fp: 4.0000 - tn: 297.0000 - fn: 9.0000 - precision: 0.9866 - recall: 0.9703 - auc: 0.9972 - accuracy: 0.9785 - val_loss: 0.4207 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 23.0000 - val_precision: 0.8030 - val_recall: 0.6974 - val_auc: 0.8863 - val_accuracy: 0.7600\n",
      "Epoch 58/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1648 - tp: 289.0000 - fp: 7.0000 - tn: 287.0000 - fn: 9.0000 - precision: 0.9764 - recall: 0.9698 - auc: 0.9972 - accuracy: 0.9730\n",
      "Epoch 00058: val_loss did not improve from 0.41628\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1646 - tp: 294.0000 - fp: 7.0000 - tn: 294.0000 - fn: 9.0000 - precision: 0.9767 - recall: 0.9703 - auc: 0.9971 - accuracy: 0.9735 - val_loss: 0.4234 - val_tp: 64.0000 - val_fp: 19.0000 - val_tn: 55.0000 - val_fn: 12.0000 - val_precision: 0.7711 - val_recall: 0.8421 - val_auc: 0.8822 - val_accuracy: 0.7933\n",
      "Epoch 59/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1576 - tp: 274.0000 - fp: 8.0000 - tn: 270.0000 - fn: 8.0000 - precision: 0.9716 - recall: 0.9716 - auc: 0.9984 - accuracy: 0.9714\n",
      "Epoch 00059: val_loss improved from 0.41628 to 0.41585, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.1561 - tp: 295.0000 - fp: 8.0000 - tn: 293.0000 - fn: 8.0000 - precision: 0.9736 - recall: 0.9736 - auc: 0.9985 - accuracy: 0.9735 - val_loss: 0.4158 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 61.0000 - val_fn: 23.0000 - val_precision: 0.8030 - val_recall: 0.6974 - val_auc: 0.8902 - val_accuracy: 0.7600\n",
      "Epoch 60/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1520 - tp: 275.0000 - fp: 6.0000 - tn: 273.0000 - fn: 6.0000 - precision: 0.9786 - recall: 0.9786 - auc: 0.9987 - accuracy: 0.9786\n",
      "Epoch 00060: val_loss did not improve from 0.41585\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1555 - tp: 297.0000 - fp: 8.0000 - tn: 293.0000 - fn: 6.0000 - precision: 0.9738 - recall: 0.9802 - auc: 0.9982 - accuracy: 0.9768 - val_loss: 0.4248 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 57.0000 - val_fn: 17.0000 - val_precision: 0.7763 - val_recall: 0.7763 - val_auc: 0.8818 - val_accuracy: 0.7733\n",
      "Epoch 61/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1621 - tp: 262.0000 - fp: 5.0000 - tn: 279.0000 - fn: 14.0000 - precision: 0.9813 - recall: 0.9493 - auc: 0.9972 - accuracy: 0.9661\n",
      "Epoch 00061: val_loss did not improve from 0.41585\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.1617 - tp: 289.0000 - fp: 5.0000 - tn: 296.0000 - fn: 14.0000 - precision: 0.9830 - recall: 0.9538 - auc: 0.9975 - accuracy: 0.9685 - val_loss: 0.4248 - val_tp: 62.0000 - val_fp: 18.0000 - val_tn: 56.0000 - val_fn: 14.0000 - val_precision: 0.7750 - val_recall: 0.8158 - val_auc: 0.8820 - val_accuracy: 0.7867\n",
      "Epoch 62/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1537 - tp: 289.0000 - fp: 9.0000 - tn: 273.0000 - fn: 5.0000 - precision: 0.9698 - recall: 0.9830 - auc: 0.9981 - accuracy: 0.9757\n",
      "Epoch 00062: val_loss did not improve from 0.41585\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1525 - tp: 298.0000 - fp: 9.0000 - tn: 292.0000 - fn: 5.0000 - precision: 0.9707 - recall: 0.9835 - auc: 0.9982 - accuracy: 0.9768 - val_loss: 0.4166 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 20.0000 - val_precision: 0.7887 - val_recall: 0.7368 - val_auc: 0.8844 - val_accuracy: 0.7667\n",
      "Epoch 63/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1524 - tp: 272.0000 - fp: 5.0000 - tn: 272.0000 - fn: 11.0000 - precision: 0.9819 - recall: 0.9611 - auc: 0.9976 - accuracy: 0.9714\n",
      "Epoch 00063: val_loss did not improve from 0.41585\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1529 - tp: 292.0000 - fp: 6.0000 - tn: 295.0000 - fn: 11.0000 - precision: 0.9799 - recall: 0.9637 - auc: 0.9975 - accuracy: 0.9719 - val_loss: 0.4414 - val_tp: 66.0000 - val_fp: 19.0000 - val_tn: 55.0000 - val_fn: 10.0000 - val_precision: 0.7765 - val_recall: 0.8684 - val_auc: 0.8810 - val_accuracy: 0.8067\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1478 - tp: 299.0000 - fp: 9.0000 - tn: 292.0000 - fn: 4.0000 - precision: 0.9708 - recall: 0.9868 - auc: 0.9971 - accuracy: 0.9785  \n",
      "Epoch 00064: val_loss did not improve from 0.41585\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1478 - tp: 299.0000 - fp: 9.0000 - tn: 292.0000 - fn: 4.0000 - precision: 0.9708 - recall: 0.9868 - auc: 0.9971 - accuracy: 0.9785 - val_loss: 0.4286 - val_tp: 52.0000 - val_fp: 10.0000 - val_tn: 64.0000 - val_fn: 24.0000 - val_precision: 0.8387 - val_recall: 0.6842 - val_auc: 0.8896 - val_accuracy: 0.7733\n",
      "Epoch 65/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1430 - tp: 283.0000 - fp: 6.0000 - tn: 281.0000 - fn: 6.0000 - precision: 0.9792 - recall: 0.9792 - auc: 0.9985 - accuracy: 0.9792\n",
      "Epoch 00065: val_loss improved from 0.41585 to 0.40710, saving model to models/lidc-3d-cnn.h5\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.1452 - tp: 297.0000 - fp: 7.0000 - tn: 294.0000 - fn: 6.0000 - precision: 0.9770 - recall: 0.9802 - auc: 0.9984 - accuracy: 0.9785 - val_loss: 0.4071 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 19.0000 - val_precision: 0.7917 - val_recall: 0.7500 - val_auc: 0.8928 - val_accuracy: 0.7733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1418 - tp: 279.0000 - fp: 3.0000 - tn: 273.0000 - fn: 5.0000 - precision: 0.9894 - recall: 0.9824 - auc: 0.9992 - accuracy: 0.9857\n",
      "Epoch 00066: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1399 - tp: 298.0000 - fp: 4.0000 - tn: 297.0000 - fn: 5.0000 - precision: 0.9868 - recall: 0.9835 - auc: 0.9992 - accuracy: 0.9851 - val_loss: 0.4259 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 64.0000 - val_fn: 26.0000 - val_precision: 0.8333 - val_recall: 0.6579 - val_auc: 0.8914 - val_accuracy: 0.7600\n",
      "Epoch 67/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1415 - tp: 272.0000 - fp: 6.0000 - tn: 277.0000 - fn: 5.0000 - precision: 0.9784 - recall: 0.9819 - auc: 0.9982 - accuracy: 0.9804\n",
      "Epoch 00067: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1404 - tp: 298.0000 - fp: 6.0000 - tn: 295.0000 - fn: 5.0000 - precision: 0.9803 - recall: 0.9835 - auc: 0.9984 - accuracy: 0.9818 - val_loss: 0.4221 - val_tp: 52.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 24.0000 - val_precision: 0.8254 - val_recall: 0.6842 - val_auc: 0.8928 - val_accuracy: 0.7667\n",
      "Epoch 68/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1390 - tp: 264.0000 - fp: 7.0000 - tn: 278.0000 - fn: 11.0000 - precision: 0.9742 - recall: 0.9600 - auc: 0.9983 - accuracy: 0.9679\n",
      "Epoch 00068: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1381 - tp: 291.0000 - fp: 7.0000 - tn: 294.0000 - fn: 12.0000 - precision: 0.9765 - recall: 0.9604 - auc: 0.9984 - accuracy: 0.9685 - val_loss: 0.4226 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 57.0000 - val_fn: 16.0000 - val_precision: 0.7792 - val_recall: 0.7895 - val_auc: 0.8844 - val_accuracy: 0.7800\n",
      "Epoch 69/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1372 - tp: 291.0000 - fp: 8.0000 - tn: 289.0000 - fn: 4.0000 - precision: 0.9732 - recall: 0.9864 - auc: 0.9979 - accuracy: 0.9797\n",
      "Epoch 00069: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1367 - tp: 299.0000 - fp: 8.0000 - tn: 293.0000 - fn: 4.0000 - precision: 0.9739 - recall: 0.9868 - auc: 0.9980 - accuracy: 0.9801 - val_loss: 0.4138 - val_tp: 52.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 24.0000 - val_precision: 0.8254 - val_recall: 0.6842 - val_auc: 0.8922 - val_accuracy: 0.7667\n",
      "Epoch 70/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1256 - tp: 290.0000 - fp: 2.0000 - tn: 295.0000 - fn: 5.0000 - precision: 0.9932 - recall: 0.9831 - auc: 0.9997 - accuracy: 0.9882\n",
      "Epoch 00070: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1260 - tp: 298.0000 - fp: 2.0000 - tn: 299.0000 - fn: 5.0000 - precision: 0.9933 - recall: 0.9835 - auc: 0.9997 - accuracy: 0.9884 - val_loss: 0.4218 - val_tp: 51.0000 - val_fp: 12.0000 - val_tn: 62.0000 - val_fn: 25.0000 - val_precision: 0.8095 - val_recall: 0.6711 - val_auc: 0.8904 - val_accuracy: 0.7533\n",
      "Epoch 71/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1252 - tp: 297.0000 - fp: 6.0000 - tn: 288.0000 - fn: 1.0000 - precision: 0.9802 - recall: 0.9966 - auc: 0.9997 - accuracy: 0.9882\n",
      "Epoch 00071: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1241 - tp: 302.0000 - fp: 6.0000 - tn: 295.0000 - fn: 1.0000 - precision: 0.9805 - recall: 0.9967 - auc: 0.9997 - accuracy: 0.9884 - val_loss: 0.4155 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 22.0000 - val_precision: 0.7941 - val_recall: 0.7105 - val_auc: 0.8890 - val_accuracy: 0.7600\n",
      "Epoch 72/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1265 - tp: 295.0000 - fp: 4.0000 - tn: 289.0000 - fn: 4.0000 - precision: 0.9866 - recall: 0.9866 - auc: 0.9994 - accuracy: 0.9865\n",
      "Epoch 00072: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1251 - tp: 299.0000 - fp: 4.0000 - tn: 297.0000 - fn: 4.0000 - precision: 0.9868 - recall: 0.9868 - auc: 0.9995 - accuracy: 0.9868 - val_loss: 0.4137 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 20.0000 - val_precision: 0.8000 - val_recall: 0.7368 - val_auc: 0.8891 - val_accuracy: 0.7733\n",
      "Epoch 73/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1220 - tp: 296.0000 - fp: 5.0000 - tn: 288.0000 - fn: 3.0000 - precision: 0.9834 - recall: 0.9900 - auc: 0.9994 - accuracy: 0.9865\n",
      "Epoch 00073: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.1218 - tp: 300.0000 - fp: 5.0000 - tn: 296.0000 - fn: 3.0000 - precision: 0.9836 - recall: 0.9901 - auc: 0.9994 - accuracy: 0.9868 - val_loss: 0.4137 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 22.0000 - val_precision: 0.7941 - val_recall: 0.7105 - val_auc: 0.8907 - val_accuracy: 0.7600\n",
      "Epoch 74/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1207 - tp: 294.0000 - fp: 6.0000 - tn: 286.0000 - fn: 6.0000 - precision: 0.9800 - recall: 0.9800 - auc: 0.9994 - accuracy: 0.9797\n",
      "Epoch 00074: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1200 - tp: 297.0000 - fp: 6.0000 - tn: 295.0000 - fn: 6.0000 - precision: 0.9802 - recall: 0.9802 - auc: 0.9994 - accuracy: 0.9801 - val_loss: 0.4157 - val_tp: 52.0000 - val_fp: 12.0000 - val_tn: 62.0000 - val_fn: 24.0000 - val_precision: 0.8125 - val_recall: 0.6842 - val_auc: 0.8937 - val_accuracy: 0.7600\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1172 - tp: 297.0000 - fp: 5.0000 - tn: 296.0000 - fn: 6.0000 - precision: 0.9834 - recall: 0.9802 - auc: 0.9994 - accuracy: 0.9818\n",
      "Epoch 00075: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1172 - tp: 297.0000 - fp: 5.0000 - tn: 296.0000 - fn: 6.0000 - precision: 0.9834 - recall: 0.9802 - auc: 0.9994 - accuracy: 0.9818 - val_loss: 0.4177 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 23.0000 - val_precision: 0.7910 - val_recall: 0.6974 - val_auc: 0.8871 - val_accuracy: 0.7533\n",
      "Epoch 76/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1187 - tp: 286.0000 - fp: 2.0000 - tn: 297.0000 - fn: 7.0000 - precision: 0.9931 - recall: 0.9761 - auc: 0.9991 - accuracy: 0.9848  \n",
      "Epoch 00076: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1189 - tp: 296.0000 - fp: 2.0000 - tn: 299.0000 - fn: 7.0000 - precision: 0.9933 - recall: 0.9769 - auc: 0.9991 - accuracy: 0.9851 - val_loss: 0.4150 - val_tp: 52.0000 - val_fp: 14.0000 - val_tn: 60.0000 - val_fn: 24.0000 - val_precision: 0.7879 - val_recall: 0.6842 - val_auc: 0.8903 - val_accuracy: 0.7467\n",
      "Epoch 77/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1162 - tp: 294.0000 - fp: 6.0000 - tn: 290.0000 - fn: 2.0000 - precision: 0.9800 - recall: 0.9932 - auc: 0.9987 - accuracy: 0.9865\n",
      "Epoch 00077: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1164 - tp: 301.0000 - fp: 6.0000 - tn: 295.0000 - fn: 2.0000 - precision: 0.9805 - recall: 0.9934 - auc: 0.9988 - accuracy: 0.9868 - val_loss: 0.4140 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 19.0000 - val_precision: 0.7917 - val_recall: 0.7500 - val_auc: 0.8868 - val_accuracy: 0.7733\n",
      "Epoch 78/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1112 - tp: 276.0000 - fp: 4.0000 - tn: 279.0000 - fn: 1.0000 - precision: 0.9857 - recall: 0.9964 - auc: 0.9994 - accuracy: 0.9911\n",
      "Epoch 00078: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1117 - tp: 302.0000 - fp: 4.0000 - tn: 297.0000 - fn: 1.0000 - precision: 0.9869 - recall: 0.9967 - auc: 0.9994 - accuracy: 0.9917 - val_loss: 0.4250 - val_tp: 52.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 24.0000 - val_precision: 0.8254 - val_recall: 0.6842 - val_auc: 0.8922 - val_accuracy: 0.7667\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1129 - tp: 277.0000 - fp: 2.0000 - tn: 278.0000 - fn: 3.0000 - precision: 0.9928 - recall: 0.9893 - auc: 0.9995 - accuracy: 0.9911\n",
      "Epoch 00079: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1101 - tp: 300.0000 - fp: 3.0000 - tn: 298.0000 - fn: 3.0000 - precision: 0.9901 - recall: 0.9901 - auc: 0.9995 - accuracy: 0.9901 - val_loss: 0.4166 - val_tp: 64.0000 - val_fp: 18.0000 - val_tn: 56.0000 - val_fn: 12.0000 - val_precision: 0.7805 - val_recall: 0.8421 - val_auc: 0.8861 - val_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1079 - tp: 277.0000 - fp: 2.0000 - tn: 275.0000 - fn: 6.0000 - precision: 0.9928 - recall: 0.9788 - auc: 0.9996 - accuracy: 0.9857\n",
      "Epoch 00080: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1097 - tp: 297.0000 - fp: 2.0000 - tn: 299.0000 - fn: 6.0000 - precision: 0.9933 - recall: 0.9802 - auc: 0.9997 - accuracy: 0.9868 - val_loss: 0.4209 - val_tp: 52.0000 - val_fp: 11.0000 - val_tn: 63.0000 - val_fn: 24.0000 - val_precision: 0.8254 - val_recall: 0.6842 - val_auc: 0.8928 - val_accuracy: 0.7667\n",
      "Epoch 81/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1048 - tp: 294.0000 - fp: 1.0000 - tn: 295.0000 - fn: 2.0000 - precision: 0.9966 - recall: 0.9932 - auc: 0.9998 - accuracy: 0.9949   \n",
      "Epoch 00081: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1060 - tp: 301.0000 - fp: 2.0000 - tn: 299.0000 - fn: 2.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9996 - accuracy: 0.9934 - val_loss: 0.4167 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 19.0000 - val_precision: 0.7917 - val_recall: 0.7500 - val_auc: 0.8859 - val_accuracy: 0.7733\n",
      "Epoch 82/1000\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.1035 - tp: 281.0000 - fp: 3.0000 - tn: 275.0000 - fn: 1.0000 - precision: 0.9894 - recall: 0.9965 - auc: 0.9998 - accuracy: 0.9929\n",
      "Epoch 00082: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1024 - tp: 302.0000 - fp: 3.0000 - tn: 298.0000 - fn: 1.0000 - precision: 0.9902 - recall: 0.9967 - auc: 0.9998 - accuracy: 0.9934 - val_loss: 0.4343 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 66.0000 - val_fn: 27.0000 - val_precision: 0.8596 - val_recall: 0.6447 - val_auc: 0.8941 - val_accuracy: 0.7667\n",
      "Epoch 83/1000\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1082 - tp: 286.0000 - fp: 4.0000 - tn: 279.0000 - fn: 7.0000 - precision: 0.9862 - recall: 0.9761 - auc: 0.9992 - accuracy: 0.9809\n",
      "Epoch 00083: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.1099 - tp: 295.0000 - fp: 4.0000 - tn: 297.0000 - fn: 8.0000 - precision: 0.9866 - recall: 0.9736 - auc: 0.9991 - accuracy: 0.9801 - val_loss: 0.4147 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 58.0000 - val_fn: 18.0000 - val_precision: 0.7838 - val_recall: 0.7632 - val_auc: 0.8887 - val_accuracy: 0.7733\n",
      "Epoch 84/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1048 - tp: 296.0000 - fp: 6.0000 - tn: 288.0000 - fn: 2.0000 - precision: 0.9801 - recall: 0.9933 - auc: 0.9993 - accuracy: 0.9865\n",
      "Epoch 00084: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1045 - tp: 301.0000 - fp: 6.0000 - tn: 295.0000 - fn: 2.0000 - precision: 0.9805 - recall: 0.9934 - auc: 0.9993 - accuracy: 0.9868 - val_loss: 0.4170 - val_tp: 55.0000 - val_fp: 15.0000 - val_tn: 59.0000 - val_fn: 21.0000 - val_precision: 0.7857 - val_recall: 0.7237 - val_auc: 0.8853 - val_accuracy: 0.7600\n",
      "Epoch 85/1000\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1012 - tp: 294.0000 - fp: 5.0000 - tn: 292.0000 - fn: 1.0000 - precision: 0.9833 - recall: 0.9966 - auc: 0.9996 - accuracy: 0.9899    \n",
      "Epoch 00085: val_loss did not improve from 0.40710\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1004 - tp: 302.0000 - fp: 5.0000 - tn: 296.0000 - fn: 1.0000 - precision: 0.9837 - recall: 0.9967 - auc: 0.9996 - accuracy: 0.9901 - val_loss: 0.4387 - val_tp: 49.0000 - val_fp: 9.0000 - val_tn: 65.0000 - val_fn: 27.0000 - val_precision: 0.8448 - val_recall: 0.6447 - val_auc: 0.8973 - val_accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "cnn = build_3d_cnn()\n",
    "cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "time_callback = TimeEpoch()\n",
    "history = cnn.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1000,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        time_callback,\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"models/lidc-3d-cnn.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4071 - tp: 57.0000 - fp: 15.0000 - tn: 59.0000 - fn: 19.0000 - precision: 0.7917 - recall: 0.7500 - auc: 0.8928 - accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4071008265018463,\n",
       " 'tp': 57.0,\n",
       " 'fp': 15.0,\n",
       " 'tn': 59.0,\n",
       " 'fn': 19.0,\n",
       " 'precision': 0.7916666865348816,\n",
       " 'recall': 0.75,\n",
       " 'auc': 0.8927809000015259,\n",
       " 'accuracy': 0.7733333110809326}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "cnn.evaluate(val_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(history)\n",
    "plt.savefig(\"lidc-loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean time per epoch: 1.09s'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Mean time per epoch: {np.mean(time_callback.times):.2f}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spie_samples = 73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (((None, None, None, None), (None, None, None, None)), (1,)), types: ((tf.float32, tf.float32), tf.int8)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spie_dataset, spie_samples = classification_dataset(\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "print(f\"{spie_samples = }\")\n",
    "spie_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pretrained_3d_cnn(freeze_conv_layers=True):\n",
    "    pretrained_3d_cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "    if freeze_conv_layers:\n",
    "        for layer in pretrained_3d_cnn.layers:\n",
    "            if \"conv\" in layer.name:\n",
    "                layer.trainable = False\n",
    "    return pretrained_3d_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = spie_samples  # LOOCV\n",
    "k = 3\n",
    "val_perc = 0.1\n",
    "learning_rate = 1e-5\n",
    "batch_size = 8\n",
    "patience = 10\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc660e58af3495e8ff287f17a52d6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = []\n",
    "\n",
    "lidc_predictions = []\n",
    "lidc_aucs = []\n",
    "lidc_accs = []\n",
    "\n",
    "wo_pt_histories = []\n",
    "wo_pt_predictions = []\n",
    "wo_pt_aucs = []\n",
    "wo_pt_accs = []\n",
    "\n",
    "w_pt_histories = []\n",
    "w_pt_predictions = []\n",
    "w_pt_aucs = []\n",
    "w_pt_accs = []\n",
    "\n",
    "for fold_id, (train_dataset, test_dataset) in tqdm(\n",
    "    enumerate(kfolds(k, spie_dataset, cardinality=spie_samples)), total=k\n",
    "):\n",
    "    # print(f\" {fold_id = } \".center(50, \"=\"))\n",
    "    for _, y in test_dataset.as_numpy_iterator():\n",
    "        y_true.append(y[0])\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "    train_dataset, val_dataset = train_test_split(train_dataset, test_perc=val_perc)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    train_dataset = (\n",
    "        train_dataset.cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\", num_thresholds=1000),\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    lidc_aucs.append(round(test_metrics[\"auc\"], 2))\n",
    "    lidc_accs.append(round(test_metrics[\"accuracy\"], 2))\n",
    "    for test_x, _ in test_dataset.as_numpy_iterator():\n",
    "        pred_y = cnn(test_x, training=False)\n",
    "        lidc_predictions.append(pred_y.numpy()[0][0])\n",
    "\n",
    "    cnn = build_3d_cnn()\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\", num_thresholds=1000),\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "    history = cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=num_epochs,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    wo_pt_histories.append(history)\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    wo_pt_aucs.append(round(test_metrics[\"auc\"], 2))\n",
    "    wo_pt_accs.append(round(test_metrics[\"accuracy\"], 2))\n",
    "    for test_x, _ in test_dataset.as_numpy_iterator():\n",
    "        pred_y = cnn(test_x, training=False)\n",
    "        wo_pt_predictions.append(pred_y.numpy()[0][0])\n",
    "\n",
    "    cnn = build_pretrained_3d_cnn()\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-5),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\", num_thresholds=1000),\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "    history = cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=100,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    w_pt_histories.append(history)\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    w_pt_aucs.append(round(test_metrics[\"auc\"], 2))\n",
    "    w_pt_accs.append(round(test_metrics[\"accuracy\"], 2))\n",
    "    for test_x, _ in test_dataset.as_numpy_iterator():\n",
    "        pred_y = cnn(test_x, training=False)\n",
    "        w_pt_predictions.append(pred_y.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lidc_aucs = [0.67, 0.88, 0.5]\n",
      "wo_pt_aucs = [0.44, 0.67, 0.62]\n",
      "w_pt_aucs = [0.59, 0.9, 0.52]\n",
      "delta_auc = [0.15, 0.23, -0.1]\n",
      "LIDC mean AUC: 0.6833333333333333\n",
      "W/O pre-training mean AUC: 0.5766666666666667\n",
      "W/ pre-training mean AUC: 0.67\n",
      "LIDC confusion matrix:\n",
      "[[ 8 29]\n",
      " [ 1 35]]\n",
      "\n",
      "W/O pre-training confusion matrix:\n",
      "[[17 20]\n",
      " [14 22]]\n",
      "\n",
      "W/ pre-training confusion matrix:\n",
      "[[18 19]\n",
      " [13 23]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{lidc_aucs = }\")\n",
    "print(f\"{wo_pt_aucs = }\")\n",
    "print(f\"{w_pt_aucs = }\")\n",
    "delta_auc = [\n",
    "    round(w_pt_auc - wo_pt_auc, 2) for w_pt_auc, wo_pt_auc in zip(w_pt_aucs, wo_pt_aucs)\n",
    "]\n",
    "print(f\"{delta_auc = }\")\n",
    "print(f\"LIDC mean AUC: {mean(lidc_aucs)}\")\n",
    "print(f\"W/O pre-training mean AUC: {mean(wo_pt_aucs)}\")\n",
    "print(f\"W/ pre-training mean AUC: {mean(w_pt_aucs)}\")\n",
    "print(\"LIDC confusion matrix:\")\n",
    "print(f\"{tf.math.confusion_matrix(y_true, [round(x, 0) for x in lidc_predictions])}\")\n",
    "print(\"\")\n",
    "print(\"W/O pre-training confusion matrix:\")\n",
    "print(f\"{tf.math.confusion_matrix(y_true, [round(x, 0) for x in wo_pt_predictions])}\")\n",
    "print(\"\")\n",
    "print(\"W/ pre-training confusion matrix:\")\n",
    "print(f\"{tf.math.confusion_matrix(y_true, [round(x, 0) for x in w_pt_predictions])}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-fa7eef41486c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m plt.plot(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwo_pt_histories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w/o pre-training - train loss\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m plt.plot(\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "plt.plot(\n",
    "    wo_pt_histories[index].history[\"loss\"], \"--\", label=\"w/o pre-training - train loss\"\n",
    ")\n",
    "plt.plot(\n",
    "    wo_pt_histories[index].history[\"val_loss\"], label=\"w/o pre-training - val loss\"\n",
    ")\n",
    "plt.plot(\n",
    "    w_pt_histories[index].history[\"loss\"],\n",
    "    \"--\",\n",
    "    label=\"w/ pre-training, w/o conv freezing - train loss\",\n",
    ")\n",
    "plt.plot(\n",
    "    w_pt_histories[index].history[\"val_loss\"],\n",
    "    label=\"w/ pre-training, w/o conv freezing - val loss\",\n",
    ")\n",
    "plt.legend()\n",
    "# plot_loss_history(w_pt_conv_histories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "val_perc = 0.1\n",
    "learning_rate = 1e-5\n",
    "batch_size = 8\n",
    "num_epochs = 1000\n",
    "metrics = [\n",
    "    # keras.metrics.TruePositives(name=\"tp\"),\n",
    "    # keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    # keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    # keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    # keras.metrics.Precision(name=\"precision\"),\n",
    "    # keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidc_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "wo_pt_histories = []\n",
    "wo_pt_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "w_pt_histories = []\n",
    "w_pt_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "w_pt_conv_histories = []\n",
    "w_pt_conv_mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "for fold_id, (train_dataset, test_dataset) in tqdm(\n",
    "    enumerate(kfolds(k, spie_dataset, cardinality=spie_samples)), total=k\n",
    "):\n",
    "    print(f\" {fold_id = } \".center(50, \"=\"))\n",
    "\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    train_dataset, val_dataset = train_test_split(train_dataset, test_perc=val_perc)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    train_dataset = (\n",
    "        train_dataset.cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    print(f\"Train size: {sum(1 for _ in train_dataset.unbatch())}\")\n",
    "    print(f\"Validation size: {sum(1 for _ in val_dataset.unbatch())}\")\n",
    "    print(f\"Test size: {sum(1 for _ in test_dataset.unbatch())}\")\n",
    "    print()\n",
    "\n",
    "    cnn = keras.models.load_model(\"models/lidc-3d-cnn.h5\")\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"LIDC training only: \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in lidc_mean_metrics:\n",
    "            lidc_mean_metrics[metric_name].update_state(metric_value)\n",
    "    print(\"\")\n",
    "\n",
    "    cnn = build_3d_cnn()\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    history = cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=1000,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=20,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    wo_pt_histories.append(history)\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"Without pretraining: \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in wo_pt_mean_metrics:\n",
    "            wo_pt_mean_metrics[metric_name].update_state(metric_value)\n",
    "    print(\"\")\n",
    "\n",
    "    cnn = build_pretrained_3d_cnn(False)\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    history = cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=1000,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=20,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    w_pt_histories.append(history)\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"With pretraining (w/o conv freezing): \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in w_pt_mean_metrics:\n",
    "            w_pt_mean_metrics[metric_name].update_state(metric_value)\n",
    "    print(\"\")\n",
    "\n",
    "    cnn = build_pretrained_3d_cnn(True)\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-5),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    history = cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=1000,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=20,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    w_pt_conv_histories.append(history)\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    print(\"With pretraining (w/ conv freezing): \")\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in w_pt_conv_mean_metrics:\n",
    "            w_pt_conv_mean_metrics[metric_name].update_state(metric_value)\n",
    "\n",
    "print(\" average \".center(50, \"=\"))\n",
    "print(\"LIDC training only: \")\n",
    "for metric_name, metric_value in lidc_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")\n",
    "print(\"\")\n",
    "print(\"Without pretraining: \")\n",
    "for metric_name, metric_value in wo_pt_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"With pretraining (w/o conv freezing): \")\n",
    "for metric_name, metric_value in w_pt_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"With pretraining (w/ conv freezing): \")\n",
    "for metric_name, metric_value in w_pt_conv_mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = w_pt_conv_histories\n",
    "_, ax = plt.subplots(nrows=2, ncols=2)\n",
    "plot_loss_history(histories[0], ax[0][0])\n",
    "# ax[0][0].set_title(\"Training=[k_2, k_3, k_4]; Test=[k_1]\")\n",
    "plot_loss_history(histories[1], ax[0][1])\n",
    "# ax[0][1].set_title(\"Training=[k_1, k_3, k_4]; Test=[k_2]\")\n",
    "plot_loss_history(histories[2], ax[1][0])\n",
    "# ax[0][1].set_title(\"Training=[k_1, k_2, k_4]; Test=[k_3]\")\n",
    "plot_loss_history(histories[3], ax[1][1])\n",
    "# ax[0][1].set_title(\"Training=[k_1, k_2, k_3]; Test=[k_4]\");\n",
    "plt.savefig(\"w-pt-conv-losses.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

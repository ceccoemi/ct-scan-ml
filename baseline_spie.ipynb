{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from statistics import mean\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import kfolds, train_test_split, classification_dataset\n",
    "from train import best_num_epochs, train_model\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from plot import plot_slice, plot_volume_animation\n",
    "from config import (\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    SMALL_PATCH_SHAPE,\n",
    "    BIG_PATCH_SHAPE,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "val_perc = 0.1\n",
    "k = 10\n",
    "patience = 30\n",
    "extra_epochs = 5\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "dropout_rate = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, total_samples = classification_dataset(\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_small = keras.Input(SMALL_PATCH_SHAPE, name=\"input_small\")\n",
    "    x_small = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_1\",\n",
    "    )(input_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"small_maxpool_1\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_2\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"small_maxpool_2\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_3\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.MaxPooling3D((1, 2, 2), name=\"small_maxpool_3\")(x_small)\n",
    "    x_small = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"small_selu_conv3d_4\",\n",
    "    )(x_small)\n",
    "    x_small = keras.layers.Flatten(name=\"flatten_small\")(x_small)\n",
    "\n",
    "    input_big = keras.Input(BIG_PATCH_SHAPE, name=\"input_big\")\n",
    "    x_big = keras.layers.MaxPooling3D((2, 2, 2), name=\"big_maxpool_0\")(input_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_1\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"big_maxpool_1\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_2\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"big_maxpool_2\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_3\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.MaxPooling3D((1, 2, 2), name=\"big_maxpool_3\")(x_big)\n",
    "    x_big = SeluConv3D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        name=\"big_selu_conv3d_4\",\n",
    "    )(x_big)\n",
    "    x_big = keras.layers.Flatten(name=\"flatten_big\")(x_big)\n",
    "\n",
    "    x = keras.layers.concatenate([x_small, x_big], name=\"concatenate\")\n",
    "    x = SeluDense(128, name=\"selu_dense\")(x)\n",
    "    x = keras.layers.AlphaDropout(dropout_rate, name=\"alpha_dropout\")(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\")(x)\n",
    "\n",
    "    cnn_3d = keras.Model(inputs=[input_small, input_big], outputs=x, name=\"3dcnn\")\n",
    "\n",
    "    return cnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\"),\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 293ms/step - loss: 0.9448 - auc: 0.4810 - accuracy: 0.5303 - val_loss: 0.5028 - val_auc: 0.0000e+00 - val_accuracy: 0.8571\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.8526 - auc: 0.5398 - accuracy: 0.4545 - val_loss: 2.3950 - val_auc: 1.0000 - val_accuracy: 0.1429\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.8700 - auc: 0.5139 - accuracy: 0.5909 - val_loss: 1.7905 - val_auc: 1.0000 - val_accuracy: 0.1429\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.8623 - auc: 0.5782 - accuracy: 0.6364 - val_loss: 0.4539 - val_auc: 0.3333 - val_accuracy: 0.8571\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.9272 - auc: 0.5370 - accuracy: 0.5455 - val_loss: 0.4217 - val_auc: 0.5000 - val_accuracy: 0.8571\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.5914 - auc: 0.7431 - accuracy: 0.6970 - val_loss: 0.9487 - val_auc: 1.0000 - val_accuracy: 0.1429\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.9221 - auc: 0.5051 - accuracy: 0.4697 - val_loss: 1.6041 - val_auc: 1.0000 - val_accuracy: 0.1429\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.7702 - auc: 0.5856 - accuracy: 0.5758 - val_loss: 0.5704 - val_auc: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.5512 - auc: 0.7866 - accuracy: 0.6970 - val_loss: 0.4470 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.6516 - auc: 0.6963 - accuracy: 0.6667 - val_loss: 0.4174 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.5851 - auc: 0.7509 - accuracy: 0.6818 - val_loss: 0.3439 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.6202 - auc: 0.7139 - accuracy: 0.6364 - val_loss: 0.3484 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.6095 - auc: 0.7398 - accuracy: 0.6364 - val_loss: 0.6936 - val_auc: 1.0000 - val_accuracy: 0.5714\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.5481 - auc: 0.7917 - accuracy: 0.6970 - val_loss: 0.9466 - val_auc: 1.0000 - val_accuracy: 0.1429\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.5826 - auc: 0.7671 - accuracy: 0.6061 - val_loss: 0.4296 - val_auc: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.5257 - auc: 0.8222 - accuracy: 0.6970 - val_loss: 0.3187 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.5370 - auc: 0.8167 - accuracy: 0.7879 - val_loss: 0.3675 - val_auc: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.5323 - auc: 0.8176 - accuracy: 0.7879 - val_loss: 0.7410 - val_auc: 1.0000 - val_accuracy: 0.5714\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.4883 - auc: 0.8611 - accuracy: 0.7879 - val_loss: 0.6008 - val_auc: 1.0000 - val_accuracy: 0.5714\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.5669 - auc: 0.7898 - accuracy: 0.7121 - val_loss: 0.2745 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.5476 - auc: 0.8153 - accuracy: 0.7424 - val_loss: 0.2841 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.5400 - auc: 0.8111 - accuracy: 0.7727 - val_loss: 0.4226 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.4325 - auc: 0.9079 - accuracy: 0.8030 - val_loss: 0.4680 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.4589 - auc: 0.8843 - accuracy: 0.7424 - val_loss: 0.4257 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.4527 - auc: 0.8829 - accuracy: 0.8030 - val_loss: 0.3649 - val_auc: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.5066 - auc: 0.8352 - accuracy: 0.7576 - val_loss: 0.2656 - val_auc: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.4119 - auc: 0.9102 - accuracy: 0.8485 - val_loss: 0.3434 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.4881 - auc: 0.8468 - accuracy: 0.8030 - val_loss: 0.7015 - val_auc: 1.0000 - val_accuracy: 0.5714\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.3493 - auc: 0.9616 - accuracy: 0.8636 - val_loss: 0.3883 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.3558 - auc: 0.9514 - accuracy: 0.8939 - val_loss: 0.2388 - val_auc: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.3970 - auc: 0.9162 - accuracy: 0.8030 - val_loss: 0.2528 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.4401 - auc: 0.8801 - accuracy: 0.8030 - val_loss: 0.5256 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.3992 - auc: 0.9028 - accuracy: 0.8030 - val_loss: 0.3281 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.3774 - auc: 0.9218 - accuracy: 0.8333 - val_loss: 0.2222 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.3747 - auc: 0.9255 - accuracy: 0.8485 - val_loss: 0.3399 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.3236 - auc: 0.9468 - accuracy: 0.8788 - val_loss: 0.5399 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.3509 - auc: 0.9375 - accuracy: 0.8788 - val_loss: 0.4328 - val_auc: 1.0000 - val_accuracy: 0.8571\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.3494 - auc: 0.9287 - accuracy: 0.9091 - val_loss: 0.1802 - val_auc: 1.0000 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'num_epochs = 7'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset = train_test_split(\n",
    "    dataset, test_perc=val_perc, cardinality=total_samples\n",
    ")\n",
    "val_dataset = val_dataset.batch(1)\n",
    "train_dataset = (\n",
    "    train_dataset.batch(batch_size)\n",
    "    .cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=64, reshuffle_each_iteration=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "cnn = build_model()\n",
    "compile_model(cnn)\n",
    "log_dir = f\"logs/baseline-spie\"\n",
    "num_epochs = best_num_epochs(\n",
    "    cnn,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    patience,\n",
    "    \"val_accuracy\",\n",
    "    log_dir,\n",
    "    verbose_training=1,\n",
    ")\n",
    "f\"{num_epochs = }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c0eb76fa2e42509883d6daa9c2e6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last accuracy: 0.8571428656578064\n",
      "Last accuracy: 0.4285714328289032\n",
      "Last accuracy: 0.8571428656578064\n",
      "Last accuracy: 0.5714285969734192\n",
      "Last accuracy: 0.7142857313156128\n",
      "Last accuracy: 0.5714285969734192\n",
      "Last accuracy: 0.7142857313156128\n",
      "Last accuracy: 0.4285714328289032\n",
      "Last accuracy: 0.2857142984867096\n",
      "Last accuracy: 0.5714285969734192\n",
      "\n",
      "==============================================\n",
      "{'accuracy': 0.6000000149011612, 'auc': 0.6649999871850014}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\"auc\": [], \"accuracy\": []}\n",
    "sess_id = 0\n",
    "for train_dataset, test_dataset in tqdm(\n",
    "    kfolds(k, dataset, cardinality=total_samples), total=k\n",
    "):\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "    train_dataset = (\n",
    "        train_dataset.batch(batch_size)\n",
    "        .cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=64, reshuffle_each_iteration=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    cnn = build_model()\n",
    "    compile_model(cnn)\n",
    "    model_fname = f\"models/baseline-spie-{sess_id}.h5\"\n",
    "    cnn = train_model(\n",
    "        cnn,\n",
    "        train_dataset,\n",
    "        num_epochs + extra_epochs,\n",
    "        model_fname,\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        if metric_name in metrics:\n",
    "            metrics[metric_name].append(metric_value)\n",
    "    print(f\"Last accuracy: {metrics['accuracy'][-1]}\")\n",
    "    sess_id += 1\n",
    "mean_metrics = {\n",
    "    metric_name: mean(metric_values)\n",
    "    for metric_name, metric_values in metrics.items()\n",
    "    if metric_name in metrics\n",
    "}\n",
    "print(\"==============================================\")\n",
    "pprint(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches, label = next(iter(test_dataset.skip(6)))\n",
    "print(f\"label: {label[0][0].numpy()}\")\n",
    "prediction = cnn(patches, training=False)\n",
    "print(f\"prediction: {prediction[0][0].numpy()}\")\n",
    "plot_volume_animation(patches[0][0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

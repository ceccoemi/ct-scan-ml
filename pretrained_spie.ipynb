{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from statistics import mean\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import kfolds, train_test_split, classification_dataset\n",
    "from train import best_num_epochs, train_model\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from plot import plot_slice, plot_volume_animation\n",
    "from config import (\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    SMALL_PATCH_SHAPE,\n",
    "    BIG_PATCH_SHAPE,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "val_perc = 0.1\n",
    "k = 10\n",
    "patience = 30\n",
    "extra_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "dropout_rate = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, total_samples = classification_dataset(\n",
    "    SPIE_SMALL_NEG_TFRECORD,\n",
    "    SPIE_BIG_NEG_TFRECORD,\n",
    "    SPIE_SMALL_POS_TFRECORD,\n",
    "    SPIE_BIG_POS_TFRECORD,\n",
    "    return_size=True,\n",
    ")\n",
    "total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    small_encoder = keras.models.load_model(\"models/autoencoder-lidc.h5\").get_layer(\"encoder\")\n",
    "    small_encoder._name = \"small_encoder\"\n",
    "    small_encoder.trainable = False\n",
    "    \n",
    "    input_small = keras.Input(SMALL_PATCH_SHAPE, name=\"input_small\")\n",
    "    x_small = small_encoder(input_small)\n",
    "    x_small = keras.layers.Flatten(name=\"flatten_small\")(x_small)\n",
    "\n",
    "    big_encoder = keras.models.load_model(\"models/autoencoder-lidc.h5\").get_layer(\"encoder\")\n",
    "    big_encoder._name = \"big_encoder\"\n",
    "    big_encoder.trainable = False\n",
    "    \n",
    "    input_big = keras.Input(BIG_PATCH_SHAPE, name=\"input_big\")\n",
    "    x_big = keras.layers.MaxPooling3D((2, 2, 2), name=\"big_maxpool_0\")(input_big)\n",
    "    x_big = big_encoder(x_big)\n",
    "    x_big = keras.layers.Flatten(name=\"flatten_big\")(x_big)\n",
    "\n",
    "    x = keras.layers.concatenate([x_small, x_big], name=\"concatenate\")\n",
    "    x = SeluDense(128, name=\"selu_dense\")(x)\n",
    "    x = keras.layers.AlphaDropout(dropout_rate, name=\"alpha_dropout\")(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\")(x)\n",
    "\n",
    "    cnn_3d = keras.Model(inputs=[input_small, input_big], outputs=x, name=\"3dcnn\")\n",
    "\n",
    "    return cnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\"),\n",
    "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.8309 - auc: 0.5287 - accuracy: 0.5455 - val_loss: 1.1766 - val_auc: 0.6667 - val_accuracy: 0.1429\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.8368 - auc: 0.5625 - accuracy: 0.5455 - val_loss: 0.7302 - val_auc: 0.6667 - val_accuracy: 0.5714\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.8783 - auc: 0.4222 - accuracy: 0.4394 - val_loss: 0.8548 - val_auc: 0.6667 - val_accuracy: 0.4286\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.6757 - auc: 0.6194 - accuracy: 0.6061 - val_loss: 0.7707 - val_auc: 0.6667 - val_accuracy: 0.7143\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.8114 - auc: 0.5083 - accuracy: 0.5303 - val_loss: 0.7833 - val_auc: 0.5833 - val_accuracy: 0.7143\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.8038 - auc: 0.5009 - accuracy: 0.4848 - val_loss: 0.8675 - val_auc: 0.5833 - val_accuracy: 0.4286\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.8573 - auc: 0.4796 - accuracy: 0.4697 - val_loss: 0.8035 - val_auc: 0.4167 - val_accuracy: 0.4286\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.7985 - auc: 0.5370 - accuracy: 0.5000 - val_loss: 0.7234 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.7595 - auc: 0.5542 - accuracy: 0.5152 - val_loss: 0.8912 - val_auc: 0.3333 - val_accuracy: 0.4286\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.6878 - auc: 0.6477 - accuracy: 0.6667 - val_loss: 0.9176 - val_auc: 0.3333 - val_accuracy: 0.4286\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.7164 - auc: 0.5954 - accuracy: 0.5303 - val_loss: 0.7837 - val_auc: 0.3333 - val_accuracy: 0.4286\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.7338 - auc: 0.5833 - accuracy: 0.5303 - val_loss: 0.7294 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.5900 - auc: 0.7495 - accuracy: 0.7424 - val_loss: 0.7545 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.6561 - auc: 0.6620 - accuracy: 0.6212 - val_loss: 0.7303 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.7677 - auc: 0.5384 - accuracy: 0.5000 - val_loss: 0.6813 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.7390 - auc: 0.5769 - accuracy: 0.5455 - val_loss: 0.7131 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.7084 - auc: 0.6120 - accuracy: 0.5455 - val_loss: 0.6561 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.6275 - auc: 0.7005 - accuracy: 0.6212 - val_loss: 0.7472 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.6173 - auc: 0.7009 - accuracy: 0.6212 - val_loss: 0.6806 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.6441 - auc: 0.6894 - accuracy: 0.6364 - val_loss: 0.6450 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.6116 - auc: 0.7347 - accuracy: 0.6818 - val_loss: 0.5863 - val_auc: 0.3333 - val_accuracy: 0.7143\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.6651 - auc: 0.6519 - accuracy: 0.5758 - val_loss: 0.6394 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.6602 - auc: 0.6833 - accuracy: 0.5758 - val_loss: 0.7237 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.5495 - auc: 0.8051 - accuracy: 0.6970 - val_loss: 0.9041 - val_auc: 0.3333 - val_accuracy: 0.2857\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.5421 - auc: 0.7995 - accuracy: 0.6970 - val_loss: 0.8926 - val_auc: 0.3333 - val_accuracy: 0.2857\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.5960 - auc: 0.7347 - accuracy: 0.6818 - val_loss: 0.8678 - val_auc: 0.3333 - val_accuracy: 0.2857\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.6188 - auc: 0.7204 - accuracy: 0.6667 - val_loss: 0.7830 - val_auc: 0.3333 - val_accuracy: 0.2857\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.6584 - auc: 0.6833 - accuracy: 0.6364 - val_loss: 0.6688 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.5634 - auc: 0.7861 - accuracy: 0.6667 - val_loss: 0.6605 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.5688 - auc: 0.7657 - accuracy: 0.7121 - val_loss: 0.6569 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.5296 - auc: 0.8176 - accuracy: 0.7576 - val_loss: 0.7036 - val_auc: 0.3333 - val_accuracy: 0.5714\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.5967 - auc: 0.7542 - accuracy: 0.7727 - val_loss: 0.7990 - val_auc: 0.3333 - val_accuracy: 0.2857\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.5249 - auc: 0.8083 - accuracy: 0.6970 - val_loss: 0.7975 - val_auc: 0.3333 - val_accuracy: 0.2857\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.4891 - auc: 0.8616 - accuracy: 0.7727 - val_loss: 0.7641 - val_auc: 0.3333 - val_accuracy: 0.2857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'num_epochs = 3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset = train_test_split(\n",
    "    dataset, test_perc=val_perc, cardinality=total_samples\n",
    ")\n",
    "val_dataset = val_dataset.batch(1)\n",
    "train_dataset = (\n",
    "    train_dataset.batch(batch_size)\n",
    "    .cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=64, reshuffle_each_iteration=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "cnn = build_model()\n",
    "compile_model(cnn)\n",
    "log_dir = f\"logs/pretrained-spie\"\n",
    "num_epochs = best_num_epochs(\n",
    "    cnn,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    patience,\n",
    "    \"val_accuracy\",\n",
    "    log_dir,\n",
    "    verbose_training=1,\n",
    ")\n",
    "f\"{num_epochs = }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e985190a94b74dfc9476984c506e8fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last accuracy: 0.8571428656578064\n",
      "Last accuracy: 0.5714285969734192\n",
      "Last accuracy: 0.8571428656578064\n",
      "Last accuracy: 0.8571428656578064\n",
      "Last accuracy: 0.2857142984867096\n",
      "Last accuracy: 0.4285714328289032\n",
      "Last accuracy: 0.8571428656578064\n",
      "Last accuracy: 0.4285714328289032\n",
      "Last accuracy: 0.1428571492433548\n",
      "Last accuracy: 0.5714285969734192\n",
      "\n",
      "==============================================\n",
      "{'accuracy': 0.5857142969965935, 'auc': 0.6033333212137222}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\"auc\": [], \"accuracy\": []}\n",
    "sess_id = 0\n",
    "for train_dataset, test_dataset in tqdm(\n",
    "    kfolds(k, dataset, cardinality=total_samples), total=k\n",
    "):\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "    train_dataset = (\n",
    "        train_dataset.batch(batch_size)\n",
    "        .cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=64, reshuffle_each_iteration=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    cnn = build_model()\n",
    "    compile_model(cnn)\n",
    "    model_fname = f\"models/pretrained-spie-{sess_id}.h5\"\n",
    "    cnn = train_model(\n",
    "        cnn,\n",
    "        train_dataset,\n",
    "        num_epochs + extra_epochs,\n",
    "        model_fname,\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        if metric_name in metrics:\n",
    "            metrics[metric_name].append(metric_value)\n",
    "    print(f\"Last accuracy: {metrics['accuracy'][-1]}\")\n",
    "    sess_id += 1\n",
    "mean_metrics = {\n",
    "    metric_name: mean(metric_values)\n",
    "    for metric_name, metric_values in metrics.items()\n",
    "    if metric_name in metrics\n",
    "}\n",
    "print(\"==============================================\")\n",
    "pprint(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches, label = next(iter(test_dataset.skip(6)))\n",
    "print(f\"label: {label[0][0].numpy()}\")\n",
    "prediction = cnn(patches, training=False)\n",
    "print(f\"prediction: {prediction[0][0].numpy()}\")\n",
    "plot_volume_animation(patches[0][0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

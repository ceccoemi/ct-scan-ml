{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy import ndimage\n",
    "\n",
    "from model import conv_block\n",
    "from data import example_to_tensor, normalize, add_channel_axis\n",
    "from plot import plot_slice, plot_animated_volume\n",
    "from config import CT_0, CT_1, CT_2, CT_3, SEED, SCAN_SHAPE\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(SEED)\n",
    "\n",
    "input_shape = (*SCAN_SHAPE, 1)\n",
    "\n",
    "epochs = 1000\n",
    "patience = 50\n",
    "batch_size = 8\n",
    "learning_rate = 0.00001\n",
    "dropout_rate = 0.5\n",
    "val_perc = 0.12  # percentage from the already splitted training test\n",
    "test_perc = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def one_hot_four_classes(x):\n",
    "    return tf.one_hot(x, depth=4, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(tfrecord_fname: str, label, cardinality=None):\n",
    "    \"\"\"Return a tensorflow Dataset (scan, one_hot_vector).\n",
    "\n",
    "    If cardinality is provided, the function will run faster.\n",
    "    \"\"\"\n",
    "    x_dataset = (\n",
    "        tf.data.TFRecordDataset(tfrecord_fname)\n",
    "        .map(example_to_tensor, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        .map(add_channel_axis, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    if not cardinality:\n",
    "        cardinality = sum(1 for _ in x_dataset)\n",
    "    y_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices([label])\n",
    "        .repeat(cardinality)\n",
    "        .map(one_hot_four_classes, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    return tf.data.Dataset.zip((x_dataset, y_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def random_rotate(volume, label):\n",
    "    \"Rotate the volume by a random degree\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        angle = tf.random.uniform(shape=(1,), minval=-180, maxval=180, dtype=tf.int32)[\n",
    "            0\n",
    "        ].numpy()\n",
    "        volume = ndimage.rotate(volume, angle, axes=(1, 2), reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def random_flip(volume, label):\n",
    "    if tf.random.uniform((1,), minval=0, maxval=2, dtype=tf.int32)[0] == 1:\n",
    "        volume = tf.reverse(volume, axis=(1,))\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_shape(volume, label):\n",
    "    volume.set_shape(input_shape)\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd6fca8a5e0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .map(lambda x, y: set_shape(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd6fca8a5e0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .map(lambda x, y: set_shape(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 48, 256, 256, 1), (None, 4)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_0_train_dataset = load_dataset(\n",
    "    CT_0.TRAIN_TFRECORD,\n",
    "    label=0,\n",
    "    cardinality=CT_0.RESAMPLED_TRAIN_SIZE,\n",
    ")\n",
    "ct_1_train_dataset = load_dataset(\n",
    "    CT_1.TRAIN_TFRECORD,\n",
    "    label=1,\n",
    "    cardinality=CT_1.RESAMPLED_TRAIN_SIZE,\n",
    ")\n",
    "ct_2_train_dataset = load_dataset(\n",
    "    CT_2.TRAIN_TFRECORD,\n",
    "    label=2,\n",
    "    cardinality=CT_2.RESAMPLED_TRAIN_SIZE,\n",
    ")\n",
    "ct_3_train_dataset = load_dataset(\n",
    "    CT_3.TRAIN_TFRECORD,\n",
    "    label=3,\n",
    "    cardinality=CT_3.RESAMPLED_TRAIN_SIZE,\n",
    ")\n",
    "train_dataset = (\n",
    "    ct_0_train_dataset.concatenate(ct_1_train_dataset)\n",
    "    .concatenate(ct_2_train_dataset)\n",
    "    .concatenate(ct_3_train_dataset)\n",
    "    .shuffle(\n",
    "        buffer_size=(\n",
    "            CT_0.RESAMPLED_TRAIN_SIZE\n",
    "            + CT_1.RESAMPLED_TRAIN_SIZE\n",
    "            + CT_2.RESAMPLED_TRAIN_SIZE\n",
    "            + CT_3.RESAMPLED_TRAIN_SIZE\n",
    "        ),\n",
    "        seed=SEED,\n",
    "        reshuffle_each_iteration=False,\n",
    "    )\n",
    "    .map(random_rotate, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    .map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # Set the volume shape because after a tf.numpy_function it loses the shape\n",
    "    .map(lambda x, y: set_shape(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=64, reshuffle_each_iteration=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, None, None, 1), (None, 4)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_0_val_dataset = load_dataset(\n",
    "    CT_0.VAL_TFRECORD,\n",
    "    label=0,\n",
    "    cardinality=CT_0.VAL_SIZE,\n",
    ")\n",
    "ct_1_val_dataset = load_dataset(\n",
    "    CT_1.VAL_TFRECORD,\n",
    "    label=1,\n",
    "    cardinality=CT_1.VAL_SIZE,\n",
    ")\n",
    "ct_2_val_dataset = load_dataset(\n",
    "    CT_2.VAL_TFRECORD,\n",
    "    label=2,\n",
    "    cardinality=CT_2.VAL_SIZE,\n",
    ")\n",
    "ct_3_val_dataset = load_dataset(\n",
    "    CT_3.VAL_TFRECORD,\n",
    "    label=3,\n",
    "    cardinality=CT_3.VAL_SIZE,\n",
    ")\n",
    "val_dataset = (\n",
    "    ct_0_val_dataset.concatenate(ct_1_val_dataset)\n",
    "    .concatenate(ct_2_val_dataset)\n",
    "    .concatenate(ct_3_val_dataset)\n",
    "    .shuffle(\n",
    "        buffer_size=(CT_0.VAL_SIZE + CT_1.VAL_SIZE + CT_2.VAL_SIZE + CT_3.VAL_SIZE),\n",
    "        seed=SEED,\n",
    "        reshuffle_each_iteration=False,\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .cache()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, None, None, None, 1), (None, 4)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_0_test_dataset = load_dataset(\n",
    "    CT_0.TEST_TFRECORD,\n",
    "    label=0,\n",
    "    cardinality=CT_0.TEST_SIZE,\n",
    ")\n",
    "ct_1_test_dataset = load_dataset(\n",
    "    CT_1.TEST_TFRECORD,\n",
    "    label=1,\n",
    "    cardinality=CT_1.TEST_SIZE,\n",
    ")\n",
    "ct_2_test_dataset = load_dataset(\n",
    "    CT_2.TEST_TFRECORD,\n",
    "    label=2,\n",
    "    cardinality=CT_2.TEST_SIZE,\n",
    ")\n",
    "ct_3_test_dataset = load_dataset(\n",
    "    CT_3.TEST_TFRECORD,\n",
    "    label=3,\n",
    "    cardinality=CT_3.TEST_SIZE,\n",
    ")\n",
    "test_dataset = (\n",
    "    ct_0_test_dataset.concatenate(ct_1_test_dataset)\n",
    "    .concatenate(ct_2_test_dataset)\n",
    "    .concatenate(ct_3_test_dataset)\n",
    "    .shuffle(\n",
    "        buffer_size=(CT_0.TEST_SIZE + CT_1.TEST_SIZE + CT_2.TEST_SIZE + CT_3.TEST_SIZE),\n",
    "        seed=SEED,\n",
    "        reshuffle_each_iteration=False,\n",
    "    )\n",
    "    .batch(batch_size)\n",
    ")\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeluConv3D = partial(\n",
    "    keras.layers.Conv3D,\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"lecun_normal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    activation=\"selu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeluDense = partial(\n",
    "    keras.layers.Dense,\n",
    "    kernel_initializer=\"lecun_normal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    activation=\"selu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_16 (Conv3D)           (None, 48, 256, 256, 32)  896       \n",
      "_________________________________________________________________\n",
      "alpha_dropout_20 (AlphaDropo (None, 48, 256, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 24, 128, 128, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 24, 128, 128, 64)  55360     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_21 (AlphaDropo (None, 24, 128, 128, 64)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 12, 64, 64, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 12, 64, 64, 128)   221312    \n",
      "_________________________________________________________________\n",
      "alpha_dropout_22 (AlphaDropo (None, 12, 64, 64, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 6, 32, 32, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 6, 32, 32, 128)    442496    \n",
      "_________________________________________________________________\n",
      "alpha_dropout_23 (AlphaDropo (None, 6, 32, 32, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 3, 16, 16, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 98304)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               50332160  \n",
      "_________________________________________________________________\n",
      "alpha_dropout_24 (AlphaDropo (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 51,054,276\n",
      "Trainable params: 51,054,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer(input_shape),\n",
    "        SeluConv3D(filters=32, kernel_size=3),\n",
    "        keras.layers.AlphaDropout(0.0),\n",
    "        keras.layers.MaxPooling3D(pool_size=2),\n",
    "        SeluConv3D(filters=64, kernel_size=3),\n",
    "        keras.layers.AlphaDropout(0.0),\n",
    "        keras.layers.MaxPooling3D(pool_size=2),\n",
    "        SeluConv3D(filters=128, kernel_size=3),\n",
    "        keras.layers.AlphaDropout(0.0),\n",
    "        keras.layers.MaxPooling3D(pool_size=2),\n",
    "        SeluConv3D(filters=128, kernel_size=3),\n",
    "        keras.layers.AlphaDropout(0.0),\n",
    "        keras.layers.MaxPooling3D(pool_size=2),\n",
    "        keras.layers.Flatten(),\n",
    "        SeluDense(units=512),\n",
    "        keras.layers.AlphaDropout(0.5),\n",
    "        keras.layers.Dense(4, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"3dcnn\",\n",
    ")\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      2/Unknown - 0s 216ms/step - loss: 2.4258 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1562s vs `on_train_batch_end` time: 0.2756s). Check your callbacks.\n",
      "    113/Unknown - 49s 430ms/step - loss: 1.7669 - accuracy: 0.3068\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.23164, saving model to models/baseline-20201106-203356.h5\n",
      "113/113 [==============================] - 110s 973ms/step - loss: 1.7669 - accuracy: 0.3068 - val_loss: 1.6687 - val_accuracy: 0.2316\n",
      "Epoch 2/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.3710 - accuracy: 0.3843\n",
      "Epoch 00002: val_accuracy improved from 0.23164 to 0.42373, saving model to models/baseline-20201106-203356.h5\n",
      "113/113 [==============================] - 110s 972ms/step - loss: 1.3710 - accuracy: 0.3843 - val_loss: 1.2178 - val_accuracy: 0.4237\n",
      "Epoch 3/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.2595 - accuracy: 0.4396\n",
      "Epoch 00003: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 55s 489ms/step - loss: 1.2595 - accuracy: 0.4396 - val_loss: 1.9395 - val_accuracy: 0.2486\n",
      "Epoch 4/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1420 - accuracy: 0.4906\n",
      "Epoch 00004: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 1.1420 - accuracy: 0.4906 - val_loss: 1.3613 - val_accuracy: 0.4237\n",
      "Epoch 5/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0483 - accuracy: 0.5393\n",
      "Epoch 00005: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 1.0483 - accuracy: 0.5393 - val_loss: 1.5874 - val_accuracy: 0.3220\n",
      "Epoch 6/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9228 - accuracy: 0.6146\n",
      "Epoch 00006: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.9228 - accuracy: 0.6146 - val_loss: 1.6512 - val_accuracy: 0.3446\n",
      "Epoch 7/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8326 - accuracy: 0.6645\n",
      "Epoch 00007: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.8326 - accuracy: 0.6645 - val_loss: 1.7993 - val_accuracy: 0.3559\n",
      "Epoch 8/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7165 - accuracy: 0.7309\n",
      "Epoch 00008: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.7165 - accuracy: 0.7309 - val_loss: 1.7159 - val_accuracy: 0.4124\n",
      "Epoch 9/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.7774\n",
      "Epoch 00009: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 493ms/step - loss: 0.6030 - accuracy: 0.7774 - val_loss: 1.8493 - val_accuracy: 0.3672\n",
      "Epoch 10/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8372\n",
      "Epoch 00010: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 493ms/step - loss: 0.4857 - accuracy: 0.8372 - val_loss: 2.2358 - val_accuracy: 0.3446\n",
      "Epoch 11/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.8726\n",
      "Epoch 00011: val_accuracy did not improve from 0.42373\n",
      "113/113 [==============================] - 56s 493ms/step - loss: 0.4284 - accuracy: 0.8726 - val_loss: 2.1078 - val_accuracy: 0.3955\n",
      "Epoch 12/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.8893\n",
      "Epoch 00012: val_accuracy improved from 0.42373 to 0.44068, saving model to models/baseline-20201106-203356.h5\n",
      "113/113 [==============================] - 110s 974ms/step - loss: 0.3447 - accuracy: 0.8893 - val_loss: 2.0901 - val_accuracy: 0.4407\n",
      "Epoch 13/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.9169\n",
      "Epoch 00013: val_accuracy improved from 0.44068 to 0.48023, saving model to models/baseline-20201106-203356.h5\n",
      "113/113 [==============================] - 110s 972ms/step - loss: 0.3122 - accuracy: 0.9169 - val_loss: 1.8438 - val_accuracy: 0.4802\n",
      "Epoch 14/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9380\n",
      "Epoch 00014: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 55s 489ms/step - loss: 0.2386 - accuracy: 0.9380 - val_loss: 2.6894 - val_accuracy: 0.3729\n",
      "Epoch 15/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9468\n",
      "Epoch 00015: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.2075 - accuracy: 0.9468 - val_loss: 2.2121 - val_accuracy: 0.4802\n",
      "Epoch 16/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9745\n",
      "Epoch 00016: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.1627 - accuracy: 0.9745 - val_loss: 3.7858 - val_accuracy: 0.2825\n",
      "Epoch 17/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9790\n",
      "Epoch 00017: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.1470 - accuracy: 0.9790 - val_loss: 2.7155 - val_accuracy: 0.4576\n",
      "Epoch 18/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9867\n",
      "Epoch 00018: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 493ms/step - loss: 0.1075 - accuracy: 0.9867 - val_loss: 3.1620 - val_accuracy: 0.3616\n",
      "Epoch 19/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9900\n",
      "Epoch 00019: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0914 - accuracy: 0.9900 - val_loss: 3.5564 - val_accuracy: 0.3616\n",
      "Epoch 20/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9978\n",
      "Epoch 00020: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0741 - accuracy: 0.9978 - val_loss: 3.0325 - val_accuracy: 0.4463\n",
      "Epoch 21/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9956\n",
      "Epoch 00021: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0593 - accuracy: 0.9956 - val_loss: 3.5793 - val_accuracy: 0.4068\n",
      "Epoch 22/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9956\n",
      "Epoch 00022: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0594 - accuracy: 0.9956 - val_loss: 3.6508 - val_accuracy: 0.4011\n",
      "Epoch 23/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9989\n",
      "Epoch 00023: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0557 - accuracy: 0.9989 - val_loss: 4.5647 - val_accuracy: 0.2994\n",
      "Epoch 24/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9989\n",
      "Epoch 00024: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0434 - accuracy: 0.9989 - val_loss: 2.8423 - val_accuracy: 0.4746\n",
      "Epoch 25/1000\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 1.0000\n",
      "Epoch 00025: val_accuracy did not improve from 0.48023\n",
      "113/113 [==============================] - 56s 492ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 3.6670 - val_accuracy: 0.4237\n",
      "Epoch 26/1000\n",
      " 62/113 [===============>..............] - ETA: 21s - loss: 0.0372 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "monitor_metric = \"val_accuracy\"\n",
    "\n",
    "start_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "best_checkpoint = f\"models/baseline-{start_time}.h5\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    best_checkpoint,\n",
    "    monitor=monitor_metric,\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=monitor_metric, patience=patience, mode=\"max\"\n",
    ")\n",
    "log_dir = f\"logs/baseline-{start_time}\"\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "with file_writer.as_default():\n",
    "    tf.summary.text(\n",
    "        \"Hyperparameters\",\n",
    "        f\"{SEED=}; \"\n",
    "        f\"{input_shape=}; \"\n",
    "        f\"{epochs=}; \"\n",
    "        f\"{patience=}; \"\n",
    "        f\"{batch_size=}; \"\n",
    "        f\"{learning_rate=}; \"\n",
    "        f\"{dropout_rate=}; \"\n",
    "        f\"{val_perc=}; \"\n",
    "        f\"{test_perc=}\",\n",
    "        step=0,\n",
    "    )\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=False,\n",
    "    profile_batch=0,\n",
    ")\n",
    "cnn.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.models.load_model(\"models/baseline-20201029-111058.h5\")\n",
    "cnn.evaluate(test_dataset, verbose=1, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.models.load_model(\"models/baseline-20201029-113438.h5\")\n",
    "cnn.evaluate(test_dataset, verbose=1, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.models.load_model(\"models/baseline-20201029-115235.h5\")\n",
    "cnn.evaluate(test_dataset, verbose=1, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_dataset.skip(5)))\n",
    "prediction = cnn(x, training=False)\n",
    "print(f\"real: {y.numpy()}, prediction: {prediction.numpy()}\")\n",
    "plot_animated_volume(x[0, :], fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_bias(dataset):\n",
    "    \"\"\"Prediction bias is the difference\n",
    "        average_labels - average_predictions\n",
    "\n",
    "    It should be near zero.\n",
    "    Return the tuple (label_avg, prediction_avg, prediction_bias)\n",
    "    \"\"\"\n",
    "    label_avg = np.mean([label.numpy()[0] for _, label in dataset.unbatch()])\n",
    "\n",
    "    def gen():\n",
    "        for x, _ in dataset:\n",
    "            yield x\n",
    "\n",
    "    x_dataset = (\n",
    "        tf.data.Dataset.from_generator(gen, tf.float32)\n",
    "        .unbatch()\n",
    "        .padded_batch(1, input_shape)\n",
    "    )\n",
    "    prediction_avg = np.mean([cnn(x, training=False).numpy()[0][0] for x in x_dataset])\n",
    "    return label_avg, prediction_avg, np.abs(label_avg - prediction_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, p, b = prediction_bias(train_dataset)\n",
    "print(f\"Labels average: {l}\")\n",
    "print(f\"Predictions average: {p}\")\n",
    "print(f\"Prediction bias: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import tfrecord_dataset, train_test_split, kfolds\n",
    "from layers import SeluConv3D, SeluDense\n",
    "from plot import plot_volume_animation\n",
    "from config import (\n",
    "    CT_0_TFRECORD,\n",
    "    CT_1_TFRECORD,\n",
    "    CT_2_TFRECORD,\n",
    "    CT_3_TFRECORD,\n",
    "    CT_4_TFRECORD,\n",
    "    SCAN_SHAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_x = tfrecord_dataset(CT_0_TFRECORD)\n",
    "# neg_samples = sum(1 for _ in neg_x)\n",
    "neg_samples = 254\n",
    "print(f\"{neg_samples = }\")\n",
    "neg_dataset = tf.data.Dataset.zip(\n",
    "    (neg_x, tf.data.Dataset.from_tensor_slices(np.int8([[0]])).repeat(neg_samples))\n",
    ")\n",
    "assert sum(1 for _ in neg_dataset) == neg_samples\n",
    "\n",
    "pos_x = tfrecord_dataset([CT_1_TFRECORD, CT_2_TFRECORD, CT_3_TFRECORD, CT_4_TFRECORD])\n",
    "# pos_samples = sum(1 for _ in pos_x)\n",
    "pos_samples = 856\n",
    "print(f\"{pos_samples = }\")\n",
    "pos_dataset = tf.data.Dataset.zip(\n",
    "    (pos_x, tf.data.Dataset.from_tensor_slices(np.int8([[1]])).repeat(pos_samples))\n",
    ")\n",
    "assert sum(1 for _ in pos_dataset) == pos_samples\n",
    "\n",
    "dataset = neg_dataset.concatenate(pos_dataset)\n",
    "# samples = sum(1 for _ in dataset)\n",
    "samples = neg_samples + pos_samples\n",
    "assert sum(1 for _ in dataset) == samples\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer(SCAN_SHAPE, name=\"input_layer\"),\n",
    "            SeluConv3D(filters=32, kernel_size=3, name=\"selu_conv3d_1\"),\n",
    "            keras.layers.MaxPool3D(2, name=\"maxpool3d_1\"),\n",
    "            SeluConv3D(filters=64, kernel_size=3, name=\"selu_conv3d_2\"),\n",
    "            keras.layers.MaxPool3D(2, name=\"maxpool3d_2\"),\n",
    "            SeluConv3D(filters=128, kernel_size=3, name=\"selu_conv3d_3\"),\n",
    "            keras.layers.MaxPool3D(2, name=\"maxpool3d_3\"),\n",
    "            SeluConv3D(filters=256, kernel_size=3, name=\"selu_conv3d_4\"),\n",
    "            keras.layers.MaxPool3D(2, name=\"maxpool3d_4\"),\n",
    "            keras.layers.Flatten(name=\"flatten\"),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_dense\"),\n",
    "        ],\n",
    "        name=\"3d_cnn\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "m = build_model()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc = 0.1\n",
    "val_perc = 0.1\n",
    "learning_rate = 1e-5\n",
    "batch_size = 8\n",
    "patience = 15\n",
    "metrics = [\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_dataset, test_dataset = train_test_split(\n",
    "    dataset, test_perc=test_perc, cardinality=samples\n",
    ")\n",
    "test_dataset = (\n",
    "    test_dataset.cache().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "train_dataset, val_dataset = train_test_split(trainval_dataset, test_perc=val_perc)\n",
    "val_dataset = (\n",
    "    val_dataset.cache().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.cache()  # must be called before shuffle\n",
    "    .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "cnn = build_model()\n",
    "cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "cnn.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1000,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"models/covid-3d-cnn.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(test_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "val_perc = 0.1\n",
    "learning_rate = 1e-5\n",
    "batch_size = 8\n",
    "patience = 15\n",
    "metrics = [\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63eb0c062040aa9785388e7f4d0c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== fold_id = 0 ===================\n",
      "loss: 0.15787240862846375\n",
      "tp: 76.0\n",
      "fp: 18.0\n",
      "tn: 12.0\n",
      "fn: 5.0\n",
      "precision: 0.8085106611251831\n",
      "recall: 0.9382715821266174\n",
      "accuracy: 0.792792797088623\n",
      "auc: 0.7814815044403076\n",
      "================== fold_id = 1 ===================\n",
      "loss: 0.1861683428287506\n",
      "tp: 70.0\n",
      "fp: 23.0\n",
      "tn: 12.0\n",
      "fn: 6.0\n",
      "precision: 0.7526881694793701\n",
      "recall: 0.9210526347160339\n",
      "accuracy: 0.7387387156486511\n",
      "auc: 0.7223684191703796\n",
      "================== fold_id = 2 ===================\n",
      "loss: 0.15484091639518738\n",
      "tp: 84.0\n",
      "fp: 21.0\n",
      "tn: 4.0\n",
      "fn: 2.0\n",
      "precision: 0.800000011920929\n",
      "recall: 0.9767441749572754\n",
      "accuracy: 0.792792797088623\n",
      "auc: 0.7609301805496216\n",
      "================== fold_id = 3 ===================\n",
      "loss: 0.17942418158054352\n",
      "tp: 74.0\n",
      "fp: 20.0\n",
      "tn: 8.0\n",
      "fn: 9.0\n",
      "precision: 0.7872340679168701\n",
      "recall: 0.891566276550293\n",
      "accuracy: 0.7387387156486511\n",
      "auc: 0.7018071413040161\n",
      "================== fold_id = 4 ===================\n",
      "loss: 0.1498459428548813\n",
      "tp: 84.0\n",
      "fp: 15.0\n",
      "tn: 5.0\n",
      "fn: 7.0\n",
      "precision: 0.8484848737716675\n",
      "recall: 0.9230769276618958\n",
      "accuracy: 0.8018018007278442\n",
      "auc: 0.6733516454696655\n",
      "================== fold_id = 5 ===================\n",
      "loss: 0.15912793576717377\n",
      "tp: 84.0\n",
      "fp: 20.0\n",
      "tn: 3.0\n",
      "fn: 4.0\n",
      "precision: 0.807692289352417\n",
      "recall: 0.9545454382896423\n",
      "accuracy: 0.7837837934494019\n",
      "auc: 0.6907114386558533\n",
      "================== fold_id = 6 ===================\n",
      "loss: 0.14278359711170197\n",
      "tp: 85.0\n",
      "fp: 16.0\n",
      "tn: 4.0\n",
      "fn: 6.0\n",
      "precision: 0.8415841460227966\n",
      "recall: 0.9340659379959106\n",
      "accuracy: 0.8018018007278442\n",
      "auc: 0.7043955326080322\n",
      "================== fold_id = 7 ===================\n",
      "loss: 0.20163355767726898\n",
      "tp: 69.0\n",
      "fp: 21.0\n",
      "tn: 7.0\n",
      "fn: 14.0\n",
      "precision: 0.7666666507720947\n",
      "recall: 0.8313252925872803\n",
      "accuracy: 0.684684693813324\n",
      "auc: 0.6277969479560852\n",
      "================== fold_id = 8 ===================\n",
      "loss: 0.16889475286006927\n",
      "tp: 84.0\n",
      "fp: 25.0\n",
      "tn: 2.0\n",
      "fn: 0.0\n",
      "precision: 0.7706422209739685\n",
      "recall: 1.0\n",
      "accuracy: 0.7747747898101807\n",
      "auc: 0.6946648955345154\n",
      "================== fold_id = 9 ===================\n",
      "loss: 0.16353844106197357\n",
      "tp: 82.0\n",
      "fp: 14.0\n",
      "tn: 4.0\n",
      "fn: 11.0\n",
      "precision: 0.8541666865348816\n",
      "recall: 0.8817204236984253\n",
      "accuracy: 0.7747747898101807\n",
      "auc: 0.6093189716339111\n",
      "\n",
      "==================== average =====================\n",
      "tp: 79.19999694824219\n",
      "fp: 19.299999237060547\n",
      "tn: 6.099999904632568\n",
      "fn: 6.400000095367432\n",
      "precision: 0.8037670254707336\n",
      "recall: 0.9252368807792664\n",
      "accuracy: 0.7684684991836548\n",
      "auc: 0.6966826319694519\n"
     ]
    }
   ],
   "source": [
    "mean_metrics = {\n",
    "    f\"{metric.name}\": keras.metrics.Mean(name=f\"mean_{metric.name}\")\n",
    "    for metric in metrics\n",
    "}\n",
    "for fold_id, (trainval_dataset, test_dataset) in tqdm(\n",
    "    enumerate(kfolds(k, dataset, cardinality=samples, seed=SEED)), total=k\n",
    "):\n",
    "    print(f\" {fold_id = } \".center(50, \"=\"))\n",
    "\n",
    "    test_dataset = (\n",
    "        test_dataset.cache().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    train_dataset, val_dataset = train_test_split(trainval_dataset, test_perc=val_perc)\n",
    "    val_dataset = (\n",
    "        val_dataset.cache().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    train_dataset = (\n",
    "        train_dataset.cache()  # must be called before shuffle\n",
    "        .shuffle(buffer_size=256, reshuffle_each_iteration=True)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    cnn = build_model()\n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    cnn.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=1000,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    test_metrics = cnn.evaluate(test_dataset, return_dict=True, verbose=0)\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "        if metric_name in mean_metrics:\n",
    "            mean_metrics[metric_name].update_state(metric_value)\n",
    "\n",
    "print(\" average \".center(50, \"=\"))\n",
    "for metric_name, metric_value in mean_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
